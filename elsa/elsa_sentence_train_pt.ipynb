{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import yaml\n",
    "\n",
    "from attlayer import AttentionWeightedAverage\n",
    "#from avglayer import MaskAverage\n",
    "from copy import deepcopy\n",
    "#from finetuning import (sampling_generator, finetuning_callbacks)\n",
    "from operator import itemgetter\n",
    "#from global_variables import NB_TOKENS, NB_EMOJI_CLASSES\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Input, Bidirectional, Embedding, Dense, Dropout, SpatialDropout1D, LSTM, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import L1L2 \n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elsa_architecture(nb_classes, nb_tokens, maxlen, feature_output=False, embed_dropout_rate=0, final_dropout_rate=0, embed_dim=300,\n",
    "                    embed_l2=1E-6, return_attention=False, load_embedding=False, pre_embedding=None, high=False, LSTM_hidden=512, LSTM_drop=0.5):\n",
    "    \"\"\"\n",
    "    Returns the DeepMoji architecture uninitialized and\n",
    "    without using the pretrained model weights.\n",
    "    # Arguments:\n",
    "        nb_classes: Number of classes in the dataset.\n",
    "        nb_tokens: Number of tokens in the dataset (i.e. vocabulary size).\n",
    "        maxlen: Maximum length of a token.\n",
    "        feature_output: If True the model returns the penultimate\n",
    "                        feature vector rather than Softmax probabilities\n",
    "                        (defaults to False).\n",
    "        embed_dropout_rate: Dropout rate for the embedding layer.\n",
    "        final_dropout_rate: Dropout rate for the final Softmax layer.\n",
    "        embed_l2: L2 regularization for the embedding layerl.\n",
    "        high: use or not the highway network\n",
    "    # Returns:\n",
    "        Model with the given parameters.\n",
    "    \"\"\"\n",
    "    class NonMasking(Layer):   \n",
    "        def __init__(self, **kwargs):   \n",
    "            self.supports_masking = True  \n",
    "            super(NonMasking, self).__init__(**kwargs)   \n",
    "\n",
    "        def build(self, input_shape):   \n",
    "            input_shape = input_shape   \n",
    "\n",
    "        def compute_mask(self, input, input_mask=None):   \n",
    "            # do not pass the mask to the next layers   \n",
    "            return None   \n",
    "\n",
    "        def call(self, x, mask=None):   \n",
    "            return x   \n",
    "\n",
    "        def get_output_shape_for(self, input_shape):   \n",
    "            return input_shape \n",
    "    # define embedding layer that turns word tokens into vectors\n",
    "    # an activation function is used to bound the values of the embedding\n",
    "    model_input = Input(shape=(maxlen,), dtype='int32')\n",
    "    embed_reg = L1L2(l2=embed_l2) if embed_l2 != 0 else None\n",
    "\n",
    "    if not load_embedding and pre_embedding is None:\n",
    "        embed = Embedding(input_dim=nb_tokens, output_dim=embed_dim, mask_zero=True,input_length=maxlen,embeddings_regularizer=embed_reg,\n",
    "                          name='embedding')\n",
    "    else:\n",
    "        embed = Embedding(input_dim=nb_tokens, output_dim=embed_dim, mask_zero=True,input_length=maxlen, weights=[pre_embedding],\n",
    "                          embeddings_regularizer=embed_reg,trainable=True, name='embedding')\n",
    "    if high:\n",
    "        x = NonMasking()(embed(model_input))\n",
    "    else:\n",
    "        x = embed(model_input)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    # entire embedding channels are dropped out instead of the\n",
    "    # normal Keras embedding dropout, which drops all channels for entire words\n",
    "    # many of the datasets contain so few words that losing one or more words can alter the emotions completely\n",
    "    if embed_dropout_rate != 0:\n",
    "        embed_drop = SpatialDropout1D(embed_dropout_rate, name='embed_drop')\n",
    "        x = embed_drop(x)\n",
    "\n",
    "    # skip-connection from embedding to output eases gradient-flow and allows access to lower-level features\n",
    "    # ordering of the way the merge is done is important for consistency with the pretrained model\n",
    "    lstm_0_output = Bidirectional(LSTM(LSTM_hidden, return_sequences=True, dropout=LSTM_drop), name=\"bi_lstm_0\" )(x)\n",
    "    lstm_1_output = Bidirectional(LSTM(LSTM_hidden, return_sequences=True, dropout=LSTM_drop), name=\"bi_lstm_1\" )(lstm_0_output)\n",
    "    x = concatenate([lstm_1_output, lstm_0_output, x])\n",
    "    if high:\n",
    "        x = TimeDistributed(Highway(activation='tanh', name=\"high\"))(x)\n",
    "    # if return_attention is True in AttentionWeightedAverage, an additional tensor\n",
    "    # representing the weight at each timestep is returned\n",
    "    weights = None\n",
    "    x = AttentionWeightedAverage(name='attlayer', return_attention=return_attention)(x)\n",
    "    #x = MaskAverage(name='attlayer', return_attention=return_attention)(x)\n",
    "    if return_attention:\n",
    "        x, weights = x\n",
    "\n",
    "    if not feature_output:\n",
    "        # output class probabilities\n",
    "        if final_dropout_rate != 0:\n",
    "            x = Dropout(final_dropout_rate)(x)\n",
    "\n",
    "        if nb_classes > 2:\n",
    "            outputs = [Dense(nb_classes, activation='softmax', name='softmax')(x)]\n",
    "        else:\n",
    "            outputs = [Dense(1, activation='sigmoid', name='softmax')(x)]\n",
    "    else:\n",
    "        # output penultimate feature vector\n",
    "        outputs = [x]\n",
    "\n",
    "    if return_attention:\n",
    "        # add the attention weights to the outputs if required\n",
    "        outputs.append(weights)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "cur_lan = \"elsa_pt\"\n",
    "maxlen = 20\n",
    "batch_size = 250\n",
    "lr = 0.001\n",
    "epoch_size = 25000\n",
    "nb_epochs = 1000\n",
    "patience = 1\n",
    "checkpoint_weight_path = \"./ckpt\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "optim = \"adam\"\n",
    "vocab_path = \"/data/elsa\"\n",
    "nb_classes=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_hidden = 512\n",
    "LSTM_drop = 0.5\n",
    "final_dropout_rate = 0.5\n",
    "embed_dropout_rate = 0.0\n",
    "high = False\n",
    "load_embedding = True\n",
    "embed_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(epoch_size/batch_size)\n",
    "\n",
    "wv_path = Path(vocab_path).joinpath(\"{:s}_wv.npy\".format(cur_lan)).as_posix()\n",
    "X_path = Path(vocab_path).joinpath(\"{:s}_X.npy\".format(cur_lan)).as_posix()\n",
    "y_path = Path(vocab_path).joinpath(\"{:s}_y.npy\".format(cur_lan)).as_posix()\n",
    "\n",
    "word_vec = np.load(wv_path, allow_pickle=True)\n",
    "input_vec, input_label = np.load(X_path, allow_pickle=True), np.load(y_path, allow_pickle=True)\n",
    "nb_tokens, input_len = len(word_vec), len(input_label)\n",
    "\n",
    "#please modify the checkpoint_weight_path\n",
    "#checkpoint_weight_path = '/storage1/user/ss/tmoji_ori/weight/tmoji-lstm-checkpoint-%s-h-1.hdf5' % cur_lan\n",
    "\n",
    "#idx_shuffle = list(range(input_len))\n",
    "#np.random.shuffle(idx_shuffle)\n",
    "#idx_train, idx_val, idx_test = idx_shuffle[ :int(input_len*0.7) ], idx_shuffle[int(input_len*0.7):int(input_len*0.9)], idx_shuffle[int(input_len*0.9):]\n",
    "\n",
    "train_end = int(input_len*0.7)\n",
    "val_end = int(input_len*0.9)\n",
    "\n",
    "(X_train, y_train) = (input_vec[:train_end], input_label[:train_end])\n",
    "(X_val, y_val) = (input_vec[train_end:val_end], input_label[train_end:val_end])\n",
    "(X_test, y_test) = (input_vec[val_end:], input_label[val_end:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2index = json.loads(open(\"/data/elsa/elsa_pt_vocab.txt\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2325142it [00:40, 57895.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate batch_size and maxlen\n",
      "mean:  13.232616437370055 median:  11.0 236157 avg:  13.232616437370055\n",
      "batch_size:  250 maxlen: 20\n"
     ]
    }
   ],
   "source": [
    "topn = 64\n",
    "def calculate_batchsize_maxlen(texts):\n",
    "    \"\"\" Calculates the maximum length in the provided texts and a suitable\n",
    "        batch size. Rounds up maxlen to the nearest multiple of ten.\n",
    "    # Arguments:\n",
    "        texts: List of inputs.\n",
    "    # Returns:\n",
    "        Batch size,\n",
    "        max length\n",
    "    \"\"\"\n",
    "    def roundup(x):\n",
    "        return int(math.ceil(x / 10.0)) * 10\n",
    "\n",
    "    print(\"calculate batch_size and maxlen\")\n",
    "    # Calculate max length of sequences considered\n",
    "    # Adjust batch_size accordingly to prevent GPU overflow\n",
    "    lengths = [len(t) for t in texts]\n",
    "    maxlen = roundup(np.percentile(lengths, 80.0))\n",
    "    batch_size = 250 if maxlen <= 100 else 50\n",
    "    print(\"mean: \", np.mean(lengths), \"median: \", np.median(lengths), len(lengths), \"avg: \", np.average(lengths))\n",
    "    print(\"batch_size: \", batch_size, \"maxlen:\", maxlen)\n",
    "    return batch_size, maxlen\n",
    "\n",
    "def most_common_emoji(emoji_freq_path, topn):\n",
    "    freq = {line.split()[0]: int(line.split()[1]) for line in open(emoji_freq_path).readlines()}\n",
    "    freq_topn = sorted(freq.items(), key=itemgetter(1), reverse=True)[:topn]\n",
    "    emoji_topn = [token2index[freq[0]] for freq in freq_topn]\n",
    "    return emoji_topn\n",
    "\n",
    "def as_ids(tokens):\n",
    "    tokens_as_id = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            tokens_as_id.append(token2index[token])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return tokens_as_id\n",
    "\n",
    "emoji_topn = most_common_emoji(\"/data/elsa/elsa_pt_emoji.txt\", topn=topn)\n",
    "emoji_topn.reverse()\n",
    "\n",
    "# filter out of topn emoji sentences\n",
    "with open(\"/data/elsa/elsa_pt_tokens.txt\", \"r\") as fi:\n",
    "    tidy_data = []\n",
    "    for line in tqdm(fi):\n",
    "        tokens = line.split()\n",
    "        id_tokens = as_ids(tokens)\n",
    "        if any(emoji in id_tokens for emoji in emoji_topn):\n",
    "            tidy_data.append(id_tokens)\n",
    "\n",
    "batch_size, maxlen = calculate_batchsize_maxlen(tidy_data)\n",
    "\n",
    "X = np.zeros((len(tidy_data), maxlen), dtype='uint32')\n",
    "y = []\n",
    "emoji_indices = defaultdict(list)\n",
    "for i, id_tokens in enumerate(tidy_data):\n",
    "    each_y = np.zeros(topn)\n",
    "    for token_id in id_tokens:\n",
    "        try:\n",
    "            emoji_index = emoji_topn.index(token_id)\n",
    "            each_y[emoji_index] = 1\n",
    "            break\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    assert each_y.sum() == 1\n",
    "    y.append(each_y)\n",
    "\n",
    "    id_tokens = [t for t in id_tokens if t not in emoji_topn]\n",
    "    X[i, :len(id_tokens)] = id_tokens[:min(maxlen, len(id_tokens))]\n",
    "\n",
    "    emoji_indices[emoji_index].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {line.split()[0]: int(line.split()[1]) for line in open(\"/data/elsa/elsa_pt_emoji.txt\").readlines()}\n",
    "freq_topn = sorted(freq.items(), key=itemgetter(1), reverse=True)[:64]\n",
    "emoji_topn = [token2index[freq[0]] for freq in freq_topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_topn.index(890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[326, 5260, 71451]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_indices[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2index['ğŸŒ’']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('â¤', 46647),\n",
       " ('ğŸ˜‚', 42699),\n",
       " ('ğŸ˜', 33172),\n",
       " ('ğŸ’œ', 21324),\n",
       " ('ğŸ˜­', 20536),\n",
       " ('ğŸ¤£', 14647),\n",
       " ('ğŸ™', 13173),\n",
       " ('ğŸ’•', 11375),\n",
       " ('ğŸ‘', 10599),\n",
       " ('ğŸ’™', 10397),\n",
       " ('\\U0001f970', 10362),\n",
       " ('â™€', 9991),\n",
       " ('ğŸ¤¦', 9615),\n",
       " ('ğŸ’›', 9437),\n",
       " ('ğŸ’š', 9134),\n",
       " ('\\U0001f97a', 9050),\n",
       " ('ğŸ˜”', 8018),\n",
       " ('ğŸ”¥', 7777),\n",
       " ('ğŸ’–', 7241),\n",
       " ('ğŸ¶', 7131),\n",
       " ('ğŸ’—', 6429),\n",
       " ('â™‚', 6379),\n",
       " ('ğŸ‘', 6313),\n",
       " ('ğŸ™Œ', 6035),\n",
       " ('ğŸ¤”', 5986),\n",
       " ('\\U0001f92a', 5984),\n",
       " ('â™¥', 5208),\n",
       " ('ğŸ¤¤', 5102),\n",
       " ('ğŸ™„', 4704),\n",
       " ('ğŸ˜…', 4623),\n",
       " ('ğŸ¤·', 4553),\n",
       " ('ğŸ˜‹', 4551),\n",
       " ('ğŸ˜˜', 4508),\n",
       " ('ğŸ’”', 4367),\n",
       " ('âœ¨', 4276),\n",
       " ('ğŸ˜ˆ', 4244),\n",
       " ('\\U0001f929', 4229),\n",
       " ('ğŸŒ•', 4102),\n",
       " ('ğŸŒ’', 4098),\n",
       " ('ğŸŒ—', 4071),\n",
       " ('ğŸŒ–', 4068),\n",
       " ('ğŸ˜', 4066),\n",
       " ('ğŸ˜¡', 3958),\n",
       " ('ğŸ¤§', 3756),\n",
       " ('ğŸ’“', 3615),\n",
       " ('ğŸŒ˜', 3565),\n",
       " ('ğŸŒ‘', 3473),\n",
       " ('ğŸ˜±', 3458),\n",
       " ('ğŸŒ“', 3413),\n",
       " ('ğŸŒ”', 3397),\n",
       " ('ğŸ’¦', 3355),\n",
       " ('ğŸ˜‰', 3255),\n",
       " ('âš ', 3226),\n",
       " ('ğŸ˜ª', 3206),\n",
       " ('ğŸ”´', 2966),\n",
       " ('ğŸ˜', 2957),\n",
       " ('ğŸ˜´', 2931),\n",
       " ('ğŸ’ª', 2890),\n",
       " ('ğŸ˜¢', 2817),\n",
       " ('ğŸ˜©', 2754),\n",
       " ('ğŸ’', 2743),\n",
       " ('âœŒ', 2720),\n",
       " ('\\U0001f92d', 2557),\n",
       " ('âš½', 2545)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27794.0\n",
      "1 19683.0\n",
      "2 17921.0\n",
      "3 10261.0\n",
      "4 9483.0\n",
      "5 6238.0\n",
      "6 8194.0\n",
      "7 3128.0\n",
      "8 3785.0\n",
      "9 3474.0\n",
      "10 5792.0\n",
      "11 1266.0\n",
      "12 6997.0\n",
      "13 1762.0\n",
      "14 2101.0\n",
      "15 7457.0\n",
      "16 5611.0\n",
      "17 4366.0\n",
      "18 2782.0\n",
      "19 5340.0\n",
      "20 1166.0\n",
      "21 860.0\n",
      "22 4230.0\n",
      "23 3606.0\n",
      "24 4355.0\n",
      "25 3784.0\n",
      "26 3253.0\n",
      "27 3341.0\n",
      "28 3575.0\n",
      "29 3285.0\n",
      "30 2972.0\n",
      "31 2696.0\n",
      "32 2304.0\n",
      "33 2799.0\n",
      "34 2340.0\n",
      "35 2199.0\n",
      "36 2272.0\n",
      "37 684.0\n",
      "38 20.0\n",
      "39 14.0\n",
      "40 9.0\n",
      "41 2470.0\n",
      "42 2123.0\n",
      "43 1961.0\n",
      "44 557.0\n",
      "45 3.0\n",
      "46 44.0\n",
      "47 1614.0\n",
      "48 21.0\n",
      "49 8.0\n",
      "50 726.0\n",
      "51 2545.0\n",
      "52 1581.0\n",
      "53 2116.0\n",
      "54 1813.0\n",
      "55 2068.0\n",
      "56 2273.0\n",
      "57 1684.0\n",
      "58 1894.0\n",
      "59 1775.0\n",
      "60 1129.0\n",
      "61 1673.0\n",
      "62 1579.0\n",
      "63 1301.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(64):\n",
    "    print(i, input_label[:, i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(input_label[int(input_len*0.7):int(input_len*0.9)].argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 200)      14168400    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 20, 200)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 20, 1024)     2920448     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 20, 1024)     6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 2248)     0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2248)         2248        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2248)         0           attlayer[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 64)           143936      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,530,584\n",
      "Trainable params: 23,530,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = elsa_architecture(nb_classes=nb_classes, nb_tokens=nb_tokens, maxlen=maxlen, final_dropout_rate=final_dropout_rate, embed_dropout_rate=embed_dropout_rate, \n",
    "                          load_embedding=True, pre_embedding=word_vec, high=high, embed_dim=embed_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 297553 samples, validate on 85015 samples\n",
      "Epoch 1/1000\n",
      "297553/297553 [==============================] - 230s 772us/step - loss: 2.5594 - acc: 0.3548 - val_loss: 2.1771 - val_acc: 0.4433\n",
      "Epoch 2/1000\n",
      "297553/297553 [==============================] - 220s 741us/step - loss: 1.9832 - acc: 0.4923 - val_loss: 1.9841 - val_acc: 0.4972\n",
      "Epoch 3/1000\n",
      "297553/297553 [==============================] - 226s 758us/step - loss: 1.6596 - acc: 0.5692 - val_loss: 1.8786 - val_acc: 0.5322\n",
      "Epoch 4/1000\n",
      "297553/297553 [==============================] - 222s 745us/step - loss: 1.4460 - acc: 0.6172 - val_loss: 1.8430 - val_acc: 0.5536\n",
      "Epoch 5/1000\n",
      "297553/297553 [==============================] - 219s 734us/step - loss: 1.3056 - acc: 0.6481 - val_loss: 1.8164 - val_acc: 0.5716\n",
      "Epoch 6/1000\n",
      "297553/297553 [==============================] - 217s 730us/step - loss: 1.2137 - acc: 0.6698 - val_loss: 1.8034 - val_acc: 0.5861\n",
      "Epoch 7/1000\n",
      "297553/297553 [==============================] - 219s 737us/step - loss: 1.1425 - acc: 0.6865 - val_loss: 1.8129 - val_acc: 0.5973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe204048940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if optim == 'adam':\n",
    "    adam = Adam(clipnorm=1, lr=lr)\n",
    "    model.compile(loss=loss, optimizer=adam, metrics=['accuracy'])\n",
    "elif optim == 'rmsprop':\n",
    "    model.compile(loss=loss, optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epochs,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto')],\n",
    "          verbose=True)\n",
    "\n",
    "#callbacks = finetuning_callbacks(checkpoint_weight_path, patience, verbose=1)\n",
    "#for i in range(2):\n",
    "    #train_gen = sampling_generator(X_train, y_train, batch_size, upsample=False, epoch_size=epoch_size)\n",
    "    #model.fit_generator(train_gen, steps_per_epoch=steps, epochs=nb_epochs,validation_data=(X_val, y_val),validation_steps=steps, callbacks=callbacks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6024748294650976\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2index = json.loads(open(\"/data/elsa/elsa_es_vocab.txt\", \"r\").read())\n",
    "\n",
    "freq = {line.split()[0]: int(line.split()[1]) for line in open(\"/data/elsa/elsa_pt_emoji.txt\").readlines()}\n",
    "freq_topn = sorted(freq.items(), key=itemgetter(1), reverse=True)[:nb_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('â¤', 46647),\n",
       " ('ğŸ˜‚', 42699),\n",
       " ('ğŸ˜', 33172),\n",
       " ('ğŸ’œ', 21324),\n",
       " ('ğŸ˜­', 20536),\n",
       " ('ğŸ¤£', 14647),\n",
       " ('ğŸ™', 13173),\n",
       " ('ğŸ’•', 11375),\n",
       " ('ğŸ‘', 10599),\n",
       " ('ğŸ’™', 10397),\n",
       " ('\\U0001f970', 10362),\n",
       " ('â™€', 9991),\n",
       " ('ğŸ¤¦', 9615),\n",
       " ('ğŸ’›', 9437),\n",
       " ('ğŸ’š', 9134),\n",
       " ('\\U0001f97a', 9050),\n",
       " ('ğŸ˜”', 8018),\n",
       " ('ğŸ”¥', 7777),\n",
       " ('ğŸ’–', 7241),\n",
       " ('ğŸ¶', 7131),\n",
       " ('ğŸ’—', 6429),\n",
       " ('â™‚', 6379),\n",
       " ('ğŸ‘', 6313),\n",
       " ('ğŸ™Œ', 6035),\n",
       " ('ğŸ¤”', 5986),\n",
       " ('\\U0001f92a', 5984),\n",
       " ('â™¥', 5208),\n",
       " ('ğŸ¤¤', 5102),\n",
       " ('ğŸ™„', 4704),\n",
       " ('ğŸ˜…', 4623),\n",
       " ('ğŸ¤·', 4553),\n",
       " ('ğŸ˜‹', 4551),\n",
       " ('ğŸ˜˜', 4508),\n",
       " ('ğŸ’”', 4367),\n",
       " ('âœ¨', 4276),\n",
       " ('ğŸ˜ˆ', 4244),\n",
       " ('\\U0001f929', 4229),\n",
       " ('ğŸŒ•', 4102),\n",
       " ('ğŸŒ’', 4098),\n",
       " ('ğŸŒ—', 4071),\n",
       " ('ğŸŒ–', 4068),\n",
       " ('ğŸ˜', 4066),\n",
       " ('ğŸ˜¡', 3958),\n",
       " ('ğŸ¤§', 3756),\n",
       " ('ğŸ’“', 3615),\n",
       " ('ğŸŒ˜', 3565),\n",
       " ('ğŸŒ‘', 3473),\n",
       " ('ğŸ˜±', 3458),\n",
       " ('ğŸŒ“', 3413),\n",
       " ('ğŸŒ”', 3397),\n",
       " ('ğŸ’¦', 3355),\n",
       " ('ğŸ˜‰', 3255),\n",
       " ('âš ', 3226),\n",
       " ('ğŸ˜ª', 3206),\n",
       " ('ğŸ”´', 2966),\n",
       " ('ğŸ˜', 2957),\n",
       " ('ğŸ˜´', 2931),\n",
       " ('ğŸ’ª', 2890),\n",
       " ('ğŸ˜¢', 2817),\n",
       " ('ğŸ˜©', 2754),\n",
       " ('ğŸ’', 2743),\n",
       " ('âœŒ', 2720),\n",
       " ('\\U0001f92d', 2557),\n",
       " ('âš½', 2545)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([e[0] for e in freq_topn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42508, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 63, does not match size of target_names, 64. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f5e508a4ed43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq_topn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                 \u001b[0;34m\"parameter\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1877\u001b[0m             )\n\u001b[1;32m   1878\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 63, does not match size of target_names, 64. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1), target_names=[e[0] for e in freq_topn]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
