{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.load(\"./embed/books_train_review_en_X.npy\")\n",
    "Xt = np.load(\"./embed/books_train_review_ja_X.npy\")\n",
    "y = np.load(\"./embed/books_train_review_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(elsa_src, elsa_tgt, label):\n",
    "    elsa_src = tf.keras.preprocessing.sequence.pad_sequences([elsa_src], dtype=elsa_src.dtype, maxlen=20)\n",
    "    elsa_tgt = tf.keras.preprocessing.sequence.pad_sequences([elsa_tgt], dtype=elsa_tgt.dtype, maxlen=50)\n",
    "    #assert elsa_src.shape == elsa_tgt.shape == (1, 20, 2248)\n",
    "    feature = {\n",
    "        \"src\":   tf.train.Feature(float_list=tf.train.FloatList(value=elsa_src.flatten().tolist())),\n",
    "#        \"src_len\":  tf.train.Feature(int64_list=tf.train.Int64List(value=[len(elsa_src)])),\n",
    "        \"tgt\":   tf.train.Feature(float_list=tf.train.FloatList(value=elsa_tgt.flatten().tolist())),\n",
    "#        \"tgt_len\": tf.train.Feature(int64_list=tf.train.Int64List(value=[len(elsa_tgt)])),\n",
    "        \"label\":  tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.python_io.TFRecordWriter(\"test.tfrecord\") as writer:\n",
    "    for i in tqdm(range(len(y))):\n",
    "        example = serialize_example(Xs[i], Xt[i], y[i])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example):\n",
    "    features = tf.parse_single_example(\n",
    "        example,\n",
    "        features={\n",
    "            'src': tf.io.VarLenFeature(tf.float32),\n",
    "#            'src': tf.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "#            'src_len': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "            'tgt': tf.io.VarLenFeature(tf.float32),\n",
    "#            'tgt': tf.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "#            'tgt_len': tf.FixedLenFeature([], tf.int64, default_value=0),            \n",
    "            'label': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "        })    \n",
    "    src = tf.reshape(features[\"src\"].values, (20, -1)) \n",
    "    tgt = tf.reshape(features[\"tgt\"].values, (50, -1)) \n",
    "    label = features[\"label\"]\n",
    "    return {\"src\": src, \"tgt\": tgt, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(['test.tfrecord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.map(parse_example).make_one_shot_iterator()\n",
    "get_next = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "     data = sess.run(get_next)\n",
    "s_depth = data[\"src\"].shape[1]\n",
    "t_depth = data[\"tgt\"].shape[1]\n",
    "[s_depth, t_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.map(parse_example).make_one_shot_iterator()\n",
    "get_next = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    i = 0\n",
    "    try:\n",
    "        while True:\n",
    "            sess.run(get_next)\n",
    "            i += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.map(parse_example).shuffle(1000).batch(32).repeat(1).make_one_shot_iterator()\n",
    "get_next = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            data = sess.run(get_next)\n",
    "            print(data)\n",
    "            break\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"src\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(data[\"src\"].numpy().reshape((1, 20, -1)) ==  tf.keras.preprocessing.sequence.pad_sequences([Xs[0]], dtype=\"float32\", maxlen=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset.shuffle(1000).batch(32).take(1):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"src\"].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tgt\"].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.shuffle(1000).batch(32).make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dataset.repeat(2).shuffle(1000).batch(32)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RepeatDataset = type(tf.data.Dataset().repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for data in dataset.repeat(1):\n",
    "    labels.append(data[\"label\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=\"test.tfrecord\")\n",
    "for string_record in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "    break\n",
    "\n",
    "np.array(example.features.feature[\"src\"].float_list.value).reshape(20, -1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
