{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from absl import flags\n",
    "from pathlib import Path\n",
    "from operator import itemgetter\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import model as nn\n",
    "importlib.reload(nn)\n",
    "\n",
    "elsa_architecture = nn.elsa_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "lang = \"ja\"\n",
    "batch_size = 250\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "patience = 3\n",
    "data_dir = \"/data/elsa2\"\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "optimizer = \"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_hidden = 512\n",
    "lstm_drop = 0.5\n",
    "final_drop = 0.5\n",
    "embed_drop = 0.0\n",
    "highway = False\n",
    "compute_class_weight = False\n",
    "multilabel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 200)      65831000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 50, 200)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 50, 1024)     2920448     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 50, 1024)     6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 2248)     0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2248)         2248        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2248)         0           attlayer[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_0 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_1 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_2 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_3 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_4 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_5 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_6 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_7 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_8 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_9 (Dense)               (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_10 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_11 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_12 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_13 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_14 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_15 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_16 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_17 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_18 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_19 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_20 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_21 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_22 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_23 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_24 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_25 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_26 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_27 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_28 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_29 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_30 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_31 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_32 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_33 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_34 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_35 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_36 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_37 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_38 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_39 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_40 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_41 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_42 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_43 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_44 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_45 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_46 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_47 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_48 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_49 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_50 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_51 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_52 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_53 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_54 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_55 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_56 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_57 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_58 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_59 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_60 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_61 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_62 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_63 (Dense)              (None, 1)            2249        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 75,193,184\n",
      "Trainable params: 75,193,184\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1721192 samples, validate on 491770 samples\n",
      "Epoch 1/100\n",
      "1721192/1721192 [==============================] - 3589s 2ms/step - loss: 3.9125 - sigmoid_0_loss: 0.2159 - sigmoid_1_loss: 0.2036 - sigmoid_2_loss: 0.1918 - sigmoid_3_loss: 0.1273 - sigmoid_4_loss: 0.1349 - sigmoid_5_loss: 0.1621 - sigmoid_6_loss: 0.1459 - sigmoid_7_loss: 0.1048 - sigmoid_8_loss: 0.1074 - sigmoid_9_loss: 0.0815 - sigmoid_10_loss: 0.1072 - sigmoid_11_loss: 0.1154 - sigmoid_12_loss: 0.1032 - sigmoid_13_loss: 0.0640 - sigmoid_14_loss: 0.0420 - sigmoid_15_loss: 0.0823 - sigmoid_16_loss: 0.0769 - sigmoid_17_loss: 0.0786 - sigmoid_18_loss: 0.0708 - sigmoid_19_loss: 0.0807 - sigmoid_20_loss: 0.0752 - sigmoid_21_loss: 0.0580 - sigmoid_22_loss: 0.0559 - sigmoid_23_loss: 0.0458 - sigmoid_24_loss: 0.0630 - sigmoid_25_loss: 0.0560 - sigmoid_26_loss: 0.0581 - sigmoid_27_loss: 0.0492 - sigmoid_28_loss: 0.0532 - sigmoid_29_loss: 0.0393 - sigmoid_30_loss: 0.0574 - sigmoid_31_loss: 0.0546 - sigmoid_32_loss: 0.0253 - sigmoid_33_loss: 0.0131 - sigmoid_34_loss: 0.0073 - sigmoid_35_loss: 0.0351 - sigmoid_36_loss: 0.0153 - sigmoid_37_loss: 0.0356 - sigmoid_38_loss: 0.0381 - sigmoid_39_loss: 0.0373 - sigmoid_40_loss: 0.0443 - sigmoid_41_loss: 0.0328 - sigmoid_42_loss: 0.0278 - sigmoid_43_loss: 0.0428 - sigmoid_44_loss: 0.0340 - sigmoid_45_loss: 0.0221 - sigmoid_46_loss: 0.0239 - sigmoid_47_loss: 0.0417 - sigmoid_48_loss: 0.0366 - sigmoid_49_loss: 0.0235 - sigmoid_50_loss: 0.0293 - sigmoid_51_loss: 0.0213 - sigmoid_52_loss: 0.0308 - sigmoid_53_loss: 0.0299 - sigmoid_54_loss: 0.0236 - sigmoid_55_loss: 0.0332 - sigmoid_56_loss: 0.0252 - sigmoid_57_loss: 0.0236 - sigmoid_58_loss: 0.0317 - sigmoid_59_loss: 0.0274 - sigmoid_60_loss: 0.0278 - sigmoid_61_loss: 0.0254 - sigmoid_62_loss: 0.0248 - sigmoid_63_loss: 0.0217 - sigmoid_0_acc: 0.9326 - sigmoid_1_acc: 0.9342 - sigmoid_2_acc: 0.9414 - sigmoid_3_acc: 0.9638 - sigmoid_4_acc: 0.9634 - sigmoid_5_acc: 0.9578 - sigmoid_6_acc: 0.9617 - sigmoid_7_acc: 0.9743 - sigmoid_8_acc: 0.9669 - sigmoid_9_acc: 0.9824 - sigmoid_10_acc: 0.9728 - sigmoid_11_acc: 0.9722 - sigmoid_12_acc: 0.9768 - sigmoid_13_acc: 0.9846 - sigmoid_14_acc: 0.9882 - sigmoid_15_acc: 0.9809 - sigmoid_16_acc: 0.9829 - sigmoid_17_acc: 0.9824 - sigmoid_18_acc: 0.9845 - sigmoid_19_acc: 0.9820 - sigmoid_20_acc: 0.9841 - sigmoid_21_acc: 0.9870 - sigmoid_22_acc: 0.9888 - sigmoid_23_acc: 0.9900 - sigmoid_24_acc: 0.9878 - sigmoid_25_acc: 0.9875 - sigmoid_26_acc: 0.9888 - sigmoid_27_acc: 0.9905 - sigmoid_28_acc: 0.9903 - sigmoid_29_acc: 0.9884 - sigmoid_30_acc: 0.9887 - sigmoid_31_acc: 0.9887 - sigmoid_32_acc: 0.9917 - sigmoid_33_acc: 0.9964 - sigmoid_34_acc: 0.9986 - sigmoid_35_acc: 0.9926 - sigmoid_36_acc: 0.9953 - sigmoid_37_acc: 0.9937 - sigmoid_38_acc: 0.9930 - sigmoid_39_acc: 0.9929 - sigmoid_40_acc: 0.9917 - sigmoid_41_acc: 0.9939 - sigmoid_42_acc: 0.9931 - sigmoid_43_acc: 0.9923 - sigmoid_44_acc: 0.9942 - sigmoid_45_acc: 0.9961 - sigmoid_46_acc: 0.9940 - sigmoid_47_acc: 0.9922 - sigmoid_48_acc: 0.9929 - sigmoid_49_acc: 0.9961 - sigmoid_50_acc: 0.9948 - sigmoid_51_acc: 0.9963 - sigmoid_52_acc: 0.9939 - sigmoid_53_acc: 0.9948 - sigmoid_54_acc: 0.9960 - sigmoid_55_acc: 0.9942 - sigmoid_56_acc: 0.9956 - sigmoid_57_acc: 0.9961 - sigmoid_58_acc: 0.9946 - sigmoid_59_acc: 0.9951 - sigmoid_60_acc: 0.9950 - sigmoid_61_acc: 0.9955 - sigmoid_62_acc: 0.9958 - sigmoid_63_acc: 0.9965 - val_loss: 3.6895 - val_sigmoid_0_loss: 0.2030 - val_sigmoid_1_loss: 0.1920 - val_sigmoid_2_loss: 0.1847 - val_sigmoid_3_loss: 0.1189 - val_sigmoid_4_loss: 0.1258 - val_sigmoid_5_loss: 0.1557 - val_sigmoid_6_loss: 0.1416 - val_sigmoid_7_loss: 0.0989 - val_sigmoid_8_loss: 0.0993 - val_sigmoid_9_loss: 0.0756 - val_sigmoid_10_loss: 0.1030 - val_sigmoid_11_loss: 0.1114 - val_sigmoid_12_loss: 0.1002 - val_sigmoid_13_loss: 0.0580 - val_sigmoid_14_loss: 0.0359 - val_sigmoid_15_loss: 0.0766 - val_sigmoid_16_loss: 0.0733 - val_sigmoid_17_loss: 0.0746 - val_sigmoid_18_loss: 0.0673 - val_sigmoid_19_loss: 0.0776 - val_sigmoid_20_loss: 0.0728 - val_sigmoid_21_loss: 0.0533 - val_sigmoid_22_loss: 0.0528 - val_sigmoid_23_loss: 0.0417 - val_sigmoid_24_loss: 0.0603 - val_sigmoid_25_loss: 0.0531 - val_sigmoid_26_loss: 0.0563 - val_sigmoid_27_loss: 0.0472 - val_sigmoid_28_loss: 0.0512 - val_sigmoid_29_loss: 0.0334 - val_sigmoid_30_loss: 0.0546 - val_sigmoid_31_loss: 0.0529 - val_sigmoid_32_loss: 0.0217 - val_sigmoid_33_loss: 0.0110 - val_sigmoid_34_loss: 0.0044 - val_sigmoid_35_loss: 0.0319 - val_sigmoid_36_loss: 0.0119 - val_sigmoid_37_loss: 0.0333 - val_sigmoid_38_loss: 0.0357 - val_sigmoid_39_loss: 0.0352 - val_sigmoid_40_loss: 0.0421 - val_sigmoid_41_loss: 0.0302 - val_sigmoid_42_loss: 0.0247 - val_sigmoid_43_loss: 0.0417 - val_sigmoid_44_loss: 0.0324 - val_sigmoid_45_loss: 0.0195 - val_sigmoid_46_loss: 0.0208 - val_sigmoid_47_loss: 0.0398 - val_sigmoid_48_loss: 0.0348 - val_sigmoid_49_loss: 0.0211 - val_sigmoid_50_loss: 0.0273 - val_sigmoid_51_loss: 0.0190 - val_sigmoid_52_loss: 0.0288 - val_sigmoid_53_loss: 0.0282 - val_sigmoid_54_loss: 0.0217 - val_sigmoid_55_loss: 0.0316 - val_sigmoid_56_loss: 0.0233 - val_sigmoid_57_loss: 0.0219 - val_sigmoid_58_loss: 0.0303 - val_sigmoid_59_loss: 0.0255 - val_sigmoid_60_loss: 0.0261 - val_sigmoid_61_loss: 0.0242 - val_sigmoid_62_loss: 0.0233 - val_sigmoid_63_loss: 0.0204 - val_sigmoid_0_acc: 0.9349 - val_sigmoid_1_acc: 0.9352 - val_sigmoid_2_acc: 0.9420 - val_sigmoid_3_acc: 0.9647 - val_sigmoid_4_acc: 0.9654 - val_sigmoid_5_acc: 0.9583 - val_sigmoid_6_acc: 0.9618 - val_sigmoid_7_acc: 0.9748 - val_sigmoid_8_acc: 0.9675 - val_sigmoid_9_acc: 0.9831 - val_sigmoid_10_acc: 0.9729 - val_sigmoid_11_acc: 0.9722 - val_sigmoid_12_acc: 0.9771 - val_sigmoid_13_acc: 0.9859 - val_sigmoid_14_acc: 0.9901 - val_sigmoid_15_acc: 0.9815 - val_sigmoid_16_acc: 0.9831 - val_sigmoid_17_acc: 0.9825 - val_sigmoid_18_acc: 0.9846 - val_sigmoid_19_acc: 0.9821 - val_sigmoid_20_acc: 0.9842 - val_sigmoid_21_acc: 0.9870 - val_sigmoid_22_acc: 0.9889 - val_sigmoid_23_acc: 0.9907 - val_sigmoid_24_acc: 0.9880 - val_sigmoid_25_acc: 0.9877 - val_sigmoid_26_acc: 0.9889 - val_sigmoid_27_acc: 0.9907 - val_sigmoid_28_acc: 0.9905 - val_sigmoid_29_acc: 0.9892 - val_sigmoid_30_acc: 0.9889 - val_sigmoid_31_acc: 0.9888 - val_sigmoid_32_acc: 0.9925 - val_sigmoid_33_acc: 0.9967 - val_sigmoid_34_acc: 0.9991 - val_sigmoid_35_acc: 0.9930 - val_sigmoid_36_acc: 0.9963 - val_sigmoid_37_acc: 0.9940 - val_sigmoid_38_acc: 0.9933 - val_sigmoid_39_acc: 0.9930 - val_sigmoid_40_acc: 0.9919 - val_sigmoid_41_acc: 0.9942 - val_sigmoid_42_acc: 0.9936 - val_sigmoid_43_acc: 0.9923 - val_sigmoid_44_acc: 0.9944 - val_sigmoid_45_acc: 0.9964 - val_sigmoid_46_acc: 0.9947 - val_sigmoid_47_acc: 0.9923 - val_sigmoid_48_acc: 0.9929 - val_sigmoid_49_acc: 0.9964 - val_sigmoid_50_acc: 0.9950 - val_sigmoid_51_acc: 0.9966 - val_sigmoid_52_acc: 0.9941 - val_sigmoid_53_acc: 0.9949 - val_sigmoid_54_acc: 0.9961 - val_sigmoid_55_acc: 0.9944 - val_sigmoid_56_acc: 0.9958 - val_sigmoid_57_acc: 0.9963 - val_sigmoid_58_acc: 0.9947 - val_sigmoid_59_acc: 0.9953 - val_sigmoid_60_acc: 0.9951 - val_sigmoid_61_acc: 0.9956 - val_sigmoid_62_acc: 0.9960 - val_sigmoid_63_acc: 0.9965\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    250/1721192 [..............................] - ETA: 1:01:08 - loss: 3.2896 - sigmoid_0_loss: 0.2371 - sigmoid_1_loss: 0.1863 - sigmoid_2_loss: 0.2301 - sigmoid_3_loss: 0.0875 - sigmoid_4_loss: 0.1461 - sigmoid_5_loss: 0.0867 - sigmoid_6_loss: 0.1147 - sigmoid_7_loss: 0.1655 - sigmoid_8_loss: 0.1096 - sigmoid_9_loss: 0.0645 - sigmoid_10_loss: 0.0885 - sigmoid_11_loss: 0.1067 - sigmoid_12_loss: 0.1153 - sigmoid_13_loss: 0.0880 - sigmoid_14_loss: 0.0339 - sigmoid_15_loss: 0.0593 - sigmoid_16_loss: 0.0778 - sigmoid_17_loss: 0.0143 - sigmoid_18_loss: 0.0670 - sigmoid_19_loss: 0.0905 - sigmoid_20_loss: 0.1229 - sigmoid_21_loss: 0.0105 - sigmoid_22_loss: 0.0121 - sigmoid_23_loss: 0.0150 - sigmoid_24_loss: 0.0267 - sigmoid_25_loss: 0.0326 - sigmoid_26_loss: 0.0722 - sigmoid_27_loss: 0.0356 - sigmoid_28_loss: 0.0612 - sigmoid_29_loss: 0.0639 - sigmoid_30_loss: 0.0117 - sigmoid_31_loss: 0.0113 - sigmoid_32_loss: 0.0144 - sigmoid_33_loss: 0.0112 - sigmoid_34_loss: 0.0047 - sigmoid_35_loss: 0.0401 - sigmoid_36_loss: 8.0049e-04 - sigmoid_37_loss: 0.0044 - sigmoid_38_loss: 0.0076 - sigmoid_39_loss: 0.0059 - sigmoid_40_loss: 0.0220 - sigmoid_41_loss: 0.0036 - sigmoid_42_loss: 0.0025 - sigmoid_43_loss: 0.0288 - sigmoid_44_loss: 0.0060 - sigmoid_45_loss: 0.0019 - sigmoid_46_loss: 0.0015 - sigmoid_47_loss: 0.0287 - sigmoid_48_loss: 0.0047 - sigmoid_49_loss: 0.0221 - sigmoid_50_loss: 0.0177 - sigmoid_51_loss: 0.0257 - sigmoid_52_loss: 0.0276 - sigmoid_53_loss: 0.0048 - sigmoid_54_loss: 0.0386 - sigmoid_55_loss: 0.0498 - sigmoid_56_loss: 0.0463 - sigmoid_57_loss: 0.0028 - sigmoid_58_loss: 0.0208 - sigmoid_59_loss: 0.0479 - sigmoid_60_loss: 0.0191 - sigmoid_61_loss: 0.0415 - sigmoid_62_loss: 0.0214 - sigmoid_63_loss: 0.0269 - sigmoid_0_acc: 0.9160 - sigmoid_1_acc: 0.9360 - sigmoid_2_acc: 0.9160 - sigmoid_3_acc: 0.9720 - sigmoid_4_acc: 0.9600 - sigmoid_5_acc: 0.9880 - sigmoid_6_acc: 0.9720 - sigmoid_7_acc: 0.9520 - sigmoid_8_acc: 0.9560 - sigmoid_9_acc: 0.9840 - sigmoid_10_acc: 0.9760 - sigmoid_11_acc: 0.9720 - sigmoid_12_acc: 0.9720 - sigmoid_13_acc: 0.9760 - sigmoid_14_acc: 0.9920 - sigmoid_15_acc: 0.9880 - sigmoid_16_acc: 0.9840 - sigmoid_17_acc: 1.0000 - sigmoid_18_acc: 0.9800 - sigmoid_19_acc: 0.9760 - sigmoid_20_acc: 0.9720 - sigmoid_21_acc: 1.0000 - sigmoid_22_acc: 1.0000 - sigmoid_23_acc: 0.9960 - sigmoid_24_acc: 0.9960 - sigmoid_25_acc: 0.9880 - sigmoid_26_acc: 0.9840 - sigmoid_27_acc: 0.9920 - sigmoid_28_acc: 0.9880 - sigmoid_29_acc: 0.9800 - sigmoid_30_acc: 1.0000 - sigmoid_31_acc: 1.0000 - sigmoid_32_acc: 0.9920 - sigmoid_33_acc: 0.9960 - sigmoid_34_acc: 0.9960 - sigmoid_35_acc: 0.9880 - sigmoid_36_acc: 1.0000 - sigmoid_37_acc: 1.0000 - sigmoid_38_acc: 1.0000 - sigmoid_39_acc: 1.0000 - sigmoid_40_acc: 0.9960 - sigmoid_41_acc: 1.0000 - sigmoid_42_acc: 1.0000 - sigmoid_43_acc: 0.9960 - sigmoid_44_acc: 1.0000 - sigmoid_45_acc: 1.0000 - sigmoid_46_acc: 1.0000 - sigmoid_47_acc: 0.9960 - sigmoid_48_acc: 1.0000 - sigmoid_49_acc: 0.9960 - sigmoid_50_acc: 0.9960 - sigmoid_51_acc: 0.9960 - sigmoid_52_acc: 0.9960 - sigmoid_53_acc: 1.0000 - sigmoid_54_acc: 0.9880 - sigmoid_55_acc: 0.9920 - sigmoid_56_acc: 0.9920 - sigmoid_57_acc: 1.0000 - sigmoid_58_acc: 0.9960 - sigmoid_59_acc: 0.9920 - sigmoid_60_acc: 0.9960 - sigmoid_61_acc: 0.9920 - sigmoid_62_acc: 0.9960 - sigmoid_63_acc: 0.9960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "    500/1721192 [..............................] - ETA: 56:33 - loss: 3.4123 - sigmoid_0_loss: 0.2136 - sigmoid_1_loss: 0.1471 - sigmoid_2_loss: 0.2003 - sigmoid_3_loss: 0.0901 - sigmoid_4_loss: 0.1574 - sigmoid_5_loss: 0.1286 - sigmoid_6_loss: 0.1128 - sigmoid_7_loss: 0.1309 - sigmoid_8_loss: 0.0964 - sigmoid_9_loss: 0.0957 - sigmoid_10_loss: 0.0748 - sigmoid_11_loss: 0.0869 - sigmoid_12_loss: 0.0993 - sigmoid_13_loss: 0.0772 - sigmoid_14_loss: 0.0270 - sigmoid_15_loss: 0.0535 - sigmoid_16_loss: 0.0642 - sigmoid_17_loss: 0.0457 - sigmoid_18_loss: 0.0585 - sigmoid_19_loss: 0.1083 - sigmoid_20_loss: 0.1172 - sigmoid_21_loss: 0.0202 - sigmoid_22_loss: 0.0263 - sigmoid_23_loss: 0.0285 - sigmoid_24_loss: 0.0322 - sigmoid_25_loss: 0.0336 - sigmoid_26_loss: 0.0658 - sigmoid_27_loss: 0.0394 - sigmoid_28_loss: 0.0588 - sigmoid_29_loss: 0.0459 - sigmoid_30_loss: 0.0364 - sigmoid_31_loss: 0.0363 - sigmoid_32_loss: 0.0175 - sigmoid_33_loss: 0.0074 - sigmoid_34_loss: 0.0029 - sigmoid_35_loss: 0.0273 - sigmoid_36_loss: 0.0070 - sigmoid_37_loss: 0.0272 - sigmoid_38_loss: 0.0261 - sigmoid_39_loss: 0.0265 - sigmoid_40_loss: 0.0383 - sigmoid_41_loss: 0.0230 - sigmoid_42_loss: 0.0394 - sigmoid_43_loss: 0.0481 - sigmoid_44_loss: 0.0177 - sigmoid_45_loss: 0.0026 - sigmoid_46_loss: 0.0174 - sigmoid_47_loss: 0.0262 - sigmoid_48_loss: 0.0046 - sigmoid_49_loss: 0.0126 - sigmoid_50_loss: 0.0110 - sigmoid_51_loss: 0.0168 - sigmoid_52_loss: 0.0434 - sigmoid_53_loss: 0.0307 - sigmoid_54_loss: 0.0396 - sigmoid_55_loss: 0.0531 - sigmoid_56_loss: 0.0335 - sigmoid_57_loss: 0.0126 - sigmoid_58_loss: 0.0240 - sigmoid_59_loss: 0.0260 - sigmoid_60_loss: 0.0214 - sigmoid_61_loss: 0.0323 - sigmoid_62_loss: 0.0122 - sigmoid_63_loss: 0.0320 - sigmoid_0_acc: 0.9240 - sigmoid_1_acc: 0.9520 - sigmoid_2_acc: 0.9320 - sigmoid_3_acc: 0.9700 - sigmoid_4_acc: 0.9580 - sigmoid_5_acc: 0.9740 - sigmoid_6_acc: 0.9720 - sigmoid_7_acc: 0.9640 - sigmoid_8_acc: 0.9660 - sigmoid_9_acc: 0.9760 - sigmoid_10_acc: 0.9800 - sigmoid_11_acc: 0.9800 - sigmoid_12_acc: 0.9760 - sigmoid_13_acc: 0.9780 - sigmoid_14_acc: 0.9940 - sigmoid_15_acc: 0.9880 - sigmoid_16_acc: 0.9860 - sigmoid_17_acc: 0.9920 - sigmoid_18_acc: 0.9860 - sigmoid_19_acc: 0.9720 - sigmoid_20_acc: 0.9700 - sigmoid_21_acc: 0.9960 - sigmoid_22_acc: 0.9960 - sigmoid_23_acc: 0.9920 - sigmoid_24_acc: 0.9940 - sigmoid_25_acc: 0.9880 - sigmoid_26_acc: 0.9860 - sigmoid_27_acc: 0.9900 - sigmoid_28_acc: 0.9880 - sigmoid_29_acc: 0.9880 - sigmoid_30_acc: 0.9940 - sigmoid_31_acc: 0.9940 - sigmoid_32_acc: 0.9920 - sigmoid_33_acc: 0.9980 - sigmoid_34_acc: 0.9980 - sigmoid_35_acc: 0.9920 - sigmoid_36_acc: 0.9940 - sigmoid_37_acc: 0.9960 - sigmoid_38_acc: 0.9960 - sigmoid_39_acc: 0.9960 - sigmoid_40_acc: 0.9900 - sigmoid_41_acc: 0.9960 - sigmoid_42_acc: 0.9900 - sigmoid_43_acc: 0.9900 - sigmoid_44_acc: 0.9980 - sigmoid_45_acc: 1.0000 - sigmoid_46_acc: 0.9960 - sigmoid_47_acc: 0.9960 - sigmoid_48_acc: 1.0000 - sigmoid_49_acc: 0.9980 - sigmoid_50_acc: 0.9980 - sigmoid_51_acc: 0.9960 - sigmoid_52_acc: 0.9920 - sigmoid_53_acc: 0.9940 - sigmoid_54_acc: 0.9900 - sigmoid_55_acc: 0.9900 - sigmoid_56_acc: 0.9940 - sigmoid_57_acc: 0.9980 - sigmoid_58_acc: 0.9960 - sigmoid_59_acc: 0.9960 - sigmoid_60_acc: 0.9960 - sigmoid_61_acc: 0.9940 - sigmoid_62_acc: 0.9980 - sigmoid_63_acc: 0.9940      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721192/1721192 [==============================] - 3559s 2ms/step - loss: 3.6616 - sigmoid_0_loss: 0.1990 - sigmoid_1_loss: 0.1914 - sigmoid_2_loss: 0.1829 - sigmoid_3_loss: 0.1165 - sigmoid_4_loss: 0.1244 - sigmoid_5_loss: 0.1547 - sigmoid_6_loss: 0.1405 - sigmoid_7_loss: 0.0987 - sigmoid_8_loss: 0.0973 - sigmoid_9_loss: 0.0743 - sigmoid_10_loss: 0.1014 - sigmoid_11_loss: 0.1105 - sigmoid_12_loss: 0.0994 - sigmoid_13_loss: 0.0569 - sigmoid_14_loss: 0.0354 - sigmoid_15_loss: 0.0767 - sigmoid_16_loss: 0.0719 - sigmoid_17_loss: 0.0746 - sigmoid_18_loss: 0.0666 - sigmoid_19_loss: 0.0766 - sigmoid_20_loss: 0.0725 - sigmoid_21_loss: 0.0529 - sigmoid_22_loss: 0.0523 - sigmoid_23_loss: 0.0410 - sigmoid_24_loss: 0.0603 - sigmoid_25_loss: 0.0527 - sigmoid_26_loss: 0.0561 - sigmoid_27_loss: 0.0463 - sigmoid_28_loss: 0.0513 - sigmoid_29_loss: 0.0332 - sigmoid_30_loss: 0.0541 - sigmoid_31_loss: 0.0526 - sigmoid_32_loss: 0.0209 - sigmoid_33_loss: 0.0108 - sigmoid_34_loss: 0.0043 - sigmoid_35_loss: 0.0306 - sigmoid_36_loss: 0.0118 - sigmoid_37_loss: 0.0328 - sigmoid_38_loss: 0.0355 - sigmoid_39_loss: 0.0345 - sigmoid_40_loss: 0.0418 - sigmoid_41_loss: 0.0291 - sigmoid_42_loss: 0.0244 - sigmoid_43_loss: 0.0412 - sigmoid_44_loss: 0.0324 - sigmoid_45_loss: 0.0187 - sigmoid_46_loss: 0.0205 - sigmoid_47_loss: 0.0394 - sigmoid_48_loss: 0.0340 - sigmoid_49_loss: 0.0205 - sigmoid_50_loss: 0.0266 - sigmoid_51_loss: 0.0182 - sigmoid_52_loss: 0.0282 - sigmoid_53_loss: 0.0281 - sigmoid_54_loss: 0.0217 - sigmoid_55_loss: 0.0313 - sigmoid_56_loss: 0.0229 - sigmoid_57_loss: 0.0213 - sigmoid_58_loss: 0.0303 - sigmoid_59_loss: 0.0249 - sigmoid_60_loss: 0.0262 - sigmoid_61_loss: 0.0241 - sigmoid_62_loss: 0.0233 - sigmoid_63_loss: 0.0198 - sigmoid_0_acc: 0.9358 - sigmoid_1_acc: 0.9351 - sigmoid_2_acc: 0.9422 - sigmoid_3_acc: 0.9647 - sigmoid_4_acc: 0.9654 - sigmoid_5_acc: 0.9584 - sigmoid_6_acc: 0.9618 - sigmoid_7_acc: 0.9749 - sigmoid_8_acc: 0.9679 - sigmoid_9_acc: 0.9831 - sigmoid_10_acc: 0.9729 - sigmoid_11_acc: 0.9722 - sigmoid_12_acc: 0.9771 - sigmoid_13_acc: 0.9860 - sigmoid_14_acc: 0.9904 - sigmoid_15_acc: 0.9813 - sigmoid_16_acc: 0.9831 - sigmoid_17_acc: 0.9825 - sigmoid_18_acc: 0.9847 - sigmoid_19_acc: 0.9821 - sigmoid_20_acc: 0.9842 - sigmoid_21_acc: 0.9872 - sigmoid_22_acc: 0.9889 - sigmoid_23_acc: 0.9908 - sigmoid_24_acc: 0.9880 - sigmoid_25_acc: 0.9877 - sigmoid_26_acc: 0.9889 - sigmoid_27_acc: 0.9907 - sigmoid_28_acc: 0.9904 - sigmoid_29_acc: 0.9890 - sigmoid_30_acc: 0.9889 - sigmoid_31_acc: 0.9888 - sigmoid_32_acc: 0.9923 - sigmoid_33_acc: 0.9966 - sigmoid_34_acc: 0.9991 - sigmoid_35_acc: 0.9930 - sigmoid_36_acc: 0.9964 - sigmoid_37_acc: 0.9940 - sigmoid_38_acc: 0.9933 - sigmoid_39_acc: 0.9932 - sigmoid_40_acc: 0.9919 - sigmoid_41_acc: 0.9944 - sigmoid_42_acc: 0.9937 - sigmoid_43_acc: 0.9923 - sigmoid_44_acc: 0.9944 - sigmoid_45_acc: 0.9964 - sigmoid_46_acc: 0.9948 - sigmoid_47_acc: 0.9922 - sigmoid_48_acc: 0.9929 - sigmoid_49_acc: 0.9965 - sigmoid_50_acc: 0.9950 - sigmoid_51_acc: 0.9967 - sigmoid_52_acc: 0.9940 - sigmoid_53_acc: 0.9949 - sigmoid_54_acc: 0.9962 - sigmoid_55_acc: 0.9944 - sigmoid_56_acc: 0.9958 - sigmoid_57_acc: 0.9963 - sigmoid_58_acc: 0.9946 - sigmoid_59_acc: 0.9953 - sigmoid_60_acc: 0.9951 - sigmoid_61_acc: 0.9956 - sigmoid_62_acc: 0.9960 - sigmoid_63_acc: 0.9966 - val_loss: 3.6491 - val_sigmoid_0_loss: 0.1998 - val_sigmoid_1_loss: 0.1898 - val_sigmoid_2_loss: 0.1824 - val_sigmoid_3_loss: 0.1172 - val_sigmoid_4_loss: 0.1235 - val_sigmoid_5_loss: 0.1538 - val_sigmoid_6_loss: 0.1402 - val_sigmoid_7_loss: 0.0974 - val_sigmoid_8_loss: 0.0971 - val_sigmoid_9_loss: 0.0739 - val_sigmoid_10_loss: 0.1014 - val_sigmoid_11_loss: 0.1100 - val_sigmoid_12_loss: 0.0992 - val_sigmoid_13_loss: 0.0565 - val_sigmoid_14_loss: 0.0345 - val_sigmoid_15_loss: 0.0759 - val_sigmoid_16_loss: 0.0726 - val_sigmoid_17_loss: 0.0739 - val_sigmoid_18_loss: 0.0667 - val_sigmoid_19_loss: 0.0765 - val_sigmoid_20_loss: 0.0723 - val_sigmoid_21_loss: 0.0525 - val_sigmoid_22_loss: 0.0519 - val_sigmoid_23_loss: 0.0405 - val_sigmoid_24_loss: 0.0598 - val_sigmoid_25_loss: 0.0524 - val_sigmoid_26_loss: 0.0558 - val_sigmoid_27_loss: 0.0461 - val_sigmoid_28_loss: 0.0507 - val_sigmoid_29_loss: 0.0323 - val_sigmoid_30_loss: 0.0538 - val_sigmoid_31_loss: 0.0525 - val_sigmoid_32_loss: 0.0208 - val_sigmoid_33_loss: 0.0107 - val_sigmoid_34_loss: 0.0041 - val_sigmoid_35_loss: 0.0305 - val_sigmoid_36_loss: 0.0113 - val_sigmoid_37_loss: 0.0327 - val_sigmoid_38_loss: 0.0350 - val_sigmoid_39_loss: 0.0339 - val_sigmoid_40_loss: 0.0414 - val_sigmoid_41_loss: 0.0295 - val_sigmoid_42_loss: 0.0242 - val_sigmoid_43_loss: 0.0411 - val_sigmoid_44_loss: 0.0324 - val_sigmoid_45_loss: 0.0187 - val_sigmoid_46_loss: 0.0202 - val_sigmoid_47_loss: 0.0394 - val_sigmoid_48_loss: 0.0338 - val_sigmoid_49_loss: 0.0206 - val_sigmoid_50_loss: 0.0265 - val_sigmoid_51_loss: 0.0183 - val_sigmoid_52_loss: 0.0282 - val_sigmoid_53_loss: 0.0278 - val_sigmoid_54_loss: 0.0210 - val_sigmoid_55_loss: 0.0312 - val_sigmoid_56_loss: 0.0226 - val_sigmoid_57_loss: 0.0214 - val_sigmoid_58_loss: 0.0300 - val_sigmoid_59_loss: 0.0250 - val_sigmoid_60_loss: 0.0258 - val_sigmoid_61_loss: 0.0239 - val_sigmoid_62_loss: 0.0231 - val_sigmoid_63_loss: 0.0198 - val_sigmoid_0_acc: 0.9357 - val_sigmoid_1_acc: 0.9354 - val_sigmoid_2_acc: 0.9425 - val_sigmoid_3_acc: 0.9649 - val_sigmoid_4_acc: 0.9659 - val_sigmoid_5_acc: 0.9585 - val_sigmoid_6_acc: 0.9618 - val_sigmoid_7_acc: 0.9751 - val_sigmoid_8_acc: 0.9679 - val_sigmoid_9_acc: 0.9832 - val_sigmoid_10_acc: 0.9729 - val_sigmoid_11_acc: 0.9722 - val_sigmoid_12_acc: 0.9771 - val_sigmoid_13_acc: 0.9863 - val_sigmoid_14_acc: 0.9904 - val_sigmoid_15_acc: 0.9815 - val_sigmoid_16_acc: 0.9831 - val_sigmoid_17_acc: 0.9826 - val_sigmoid_18_acc: 0.9848 - val_sigmoid_19_acc: 0.9822 - val_sigmoid_20_acc: 0.9842 - val_sigmoid_21_acc: 0.9871 - val_sigmoid_22_acc: 0.9890 - val_sigmoid_23_acc: 0.9909 - val_sigmoid_24_acc: 0.9880 - val_sigmoid_25_acc: 0.9877 - val_sigmoid_26_acc: 0.9889 - val_sigmoid_27_acc: 0.9907 - val_sigmoid_28_acc: 0.9905 - val_sigmoid_29_acc: 0.9893 - val_sigmoid_30_acc: 0.9889 - val_sigmoid_31_acc: 0.9888 - val_sigmoid_32_acc: 0.9925 - val_sigmoid_33_acc: 0.9967 - val_sigmoid_34_acc: 0.9991 - val_sigmoid_35_acc: 0.9932 - val_sigmoid_36_acc: 0.9965 - val_sigmoid_37_acc: 0.9940 - val_sigmoid_38_acc: 0.9933 - val_sigmoid_39_acc: 0.9934 - val_sigmoid_40_acc: 0.9919 - val_sigmoid_41_acc: 0.9943 - val_sigmoid_42_acc: 0.9937 - val_sigmoid_43_acc: 0.9923 - val_sigmoid_44_acc: 0.9944 - val_sigmoid_45_acc: 0.9965 - val_sigmoid_46_acc: 0.9948 - val_sigmoid_47_acc: 0.9923 - val_sigmoid_48_acc: 0.9930 - val_sigmoid_49_acc: 0.9965 - val_sigmoid_50_acc: 0.9950 - val_sigmoid_51_acc: 0.9967 - val_sigmoid_52_acc: 0.9941 - val_sigmoid_53_acc: 0.9949 - val_sigmoid_54_acc: 0.9962 - val_sigmoid_55_acc: 0.9944 - val_sigmoid_56_acc: 0.9958 - val_sigmoid_57_acc: 0.9964 - val_sigmoid_58_acc: 0.9946 - val_sigmoid_59_acc: 0.9953 - val_sigmoid_60_acc: 0.9951 - val_sigmoid_61_acc: 0.9956 - val_sigmoid_62_acc: 0.9960 - val_sigmoid_63_acc: 0.9966\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    250/1721192 [..............................] - ETA: 1:03:34 - loss: 3.4276 - sigmoid_0_loss: 0.1961 - sigmoid_1_loss: 0.1542 - sigmoid_2_loss: 0.1483 - sigmoid_3_loss: 0.1427 - sigmoid_4_loss: 0.1525 - sigmoid_5_loss: 0.1749 - sigmoid_6_loss: 0.1592 - sigmoid_7_loss: 0.0481 - sigmoid_8_loss: 0.0990 - sigmoid_9_loss: 0.0782 - sigmoid_10_loss: 0.1252 - sigmoid_11_loss: 0.0736 - sigmoid_12_loss: 0.1130 - sigmoid_13_loss: 0.0428 - sigmoid_14_loss: 0.0275 - sigmoid_15_loss: 0.0797 - sigmoid_16_loss: 0.0314 - sigmoid_17_loss: 0.0814 - sigmoid_18_loss: 0.0519 - sigmoid_19_loss: 0.0673 - sigmoid_20_loss: 0.0577 - sigmoid_21_loss: 0.0509 - sigmoid_22_loss: 0.0939 - sigmoid_23_loss: 0.0268 - sigmoid_24_loss: 0.0770 - sigmoid_25_loss: 0.0610 - sigmoid_26_loss: 0.0539 - sigmoid_27_loss: 0.0376 - sigmoid_28_loss: 0.0393 - sigmoid_29_loss: 0.0195 - sigmoid_30_loss: 0.0383 - sigmoid_31_loss: 0.0548 - sigmoid_32_loss: 0.0097 - sigmoid_33_loss: 0.0056 - sigmoid_34_loss: 0.0010 - sigmoid_35_loss: 0.0193 - sigmoid_36_loss: 0.0012 - sigmoid_37_loss: 0.0195 - sigmoid_38_loss: 0.0632 - sigmoid_39_loss: 0.0083 - sigmoid_40_loss: 0.0376 - sigmoid_41_loss: 0.0045 - sigmoid_42_loss: 0.0213 - sigmoid_43_loss: 0.0073 - sigmoid_44_loss: 0.0045 - sigmoid_45_loss: 0.0033 - sigmoid_46_loss: 0.0538 - sigmoid_47_loss: 0.0433 - sigmoid_48_loss: 0.0482 - sigmoid_49_loss: 0.0049 - sigmoid_50_loss: 0.0454 - sigmoid_51_loss: 0.0030 - sigmoid_52_loss: 0.0046 - sigmoid_53_loss: 0.0401 - sigmoid_54_loss: 0.0670 - sigmoid_55_loss: 0.0419 - sigmoid_56_loss: 0.0288 - sigmoid_57_loss: 0.0038 - sigmoid_58_loss: 0.0484 - sigmoid_59_loss: 0.0232 - sigmoid_60_loss: 0.0055 - sigmoid_61_loss: 0.0065 - sigmoid_62_loss: 0.0046 - sigmoid_63_loss: 0.0286 - sigmoid_0_acc: 0.9280 - sigmoid_1_acc: 0.9480 - sigmoid_2_acc: 0.9480 - sigmoid_3_acc: 0.9520 - sigmoid_4_acc: 0.9560 - sigmoid_5_acc: 0.9520 - sigmoid_6_acc: 0.9560 - sigmoid_7_acc: 0.9840 - sigmoid_8_acc: 0.9640 - sigmoid_9_acc: 0.9840 - sigmoid_10_acc: 0.9640 - sigmoid_11_acc: 0.9800 - sigmoid_12_acc: 0.9760 - sigmoid_13_acc: 0.9880 - sigmoid_14_acc: 0.9920 - sigmoid_15_acc: 0.9760 - sigmoid_16_acc: 0.9960 - sigmoid_17_acc: 0.9800 - sigmoid_18_acc: 0.9840 - sigmoid_19_acc: 0.9800 - sigmoid_20_acc: 0.9880 - sigmoid_21_acc: 0.9880 - sigmoid_22_acc: 0.9800 - sigmoid_23_acc: 0.9960 - sigmoid_24_acc: 0.9840 - sigmoid_25_acc: 0.9880 - sigmoid_26_acc: 0.9920 - sigmoid_27_acc: 0.9920 - sigmoid_28_acc: 0.9920 - sigmoid_29_acc: 0.9960 - sigmoid_30_acc: 0.9920 - sigmoid_31_acc: 0.9880 - sigmoid_32_acc: 1.0000 - sigmoid_33_acc: 0.9960 - sigmoid_34_acc: 1.0000 - sigmoid_35_acc: 0.9960 - sigmoid_36_acc: 1.0000 - sigmoid_37_acc: 0.9960 - sigmoid_38_acc: 0.9880 - sigmoid_39_acc: 1.0000 - sigmoid_40_acc: 0.9920 - sigmoid_41_acc: 1.0000 - sigmoid_42_acc: 0.9960 - sigmoid_43_acc: 1.0000 - sigmoid_44_acc: 1.0000 - sigmoid_45_acc: 1.0000 - sigmoid_46_acc: 0.9880 - sigmoid_47_acc: 0.9880 - sigmoid_48_acc: 0.9880 - sigmoid_49_acc: 1.0000 - sigmoid_50_acc: 0.9880 - sigmoid_51_acc: 1.0000 - sigmoid_52_acc: 1.0000 - sigmoid_53_acc: 0.9920 - sigmoid_54_acc: 0.9880 - sigmoid_55_acc: 0.9920 - sigmoid_56_acc: 0.9920 - sigmoid_57_acc: 1.0000 - sigmoid_58_acc: 0.9920 - sigmoid_59_acc: 0.9960 - sigmoid_60_acc: 1.0000 - sigmoid_61_acc: 1.0000 - sigmoid_62_acc: 1.0000 - sigmoid_63_acc: 0.9920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "    500/1721192 [..............................] - ETA: 59:00 - loss: 3.5674 - sigmoid_0_loss: 0.2219 - sigmoid_1_loss: 0.1631 - sigmoid_2_loss: 0.1495 - sigmoid_3_loss: 0.1365 - sigmoid_4_loss: 0.1548 - sigmoid_5_loss: 0.1519 - sigmoid_6_loss: 0.1553 - sigmoid_7_loss: 0.0490 - sigmoid_8_loss: 0.1133 - sigmoid_9_loss: 0.0597 - sigmoid_10_loss: 0.1170 - sigmoid_11_loss: 0.0994 - sigmoid_12_loss: 0.0966 - sigmoid_13_loss: 0.0273 - sigmoid_14_loss: 0.0278 - sigmoid_15_loss: 0.0664 - sigmoid_16_loss: 0.0292 - sigmoid_17_loss: 0.1025 - sigmoid_18_loss: 0.0402 - sigmoid_19_loss: 0.0842 - sigmoid_20_loss: 0.0595 - sigmoid_21_loss: 0.0304 - sigmoid_22_loss: 0.0681 - sigmoid_23_loss: 0.0445 - sigmoid_24_loss: 0.0748 - sigmoid_25_loss: 0.0366 - sigmoid_26_loss: 0.0612 - sigmoid_27_loss: 0.0288 - sigmoid_28_loss: 0.0410 - sigmoid_29_loss: 0.0304 - sigmoid_30_loss: 0.0647 - sigmoid_31_loss: 0.0600 - sigmoid_32_loss: 0.0356 - sigmoid_33_loss: 0.0047 - sigmoid_34_loss: 7.3727e-04 - sigmoid_35_loss: 0.0351 - sigmoid_36_loss: 0.0025 - sigmoid_37_loss: 0.0244 - sigmoid_38_loss: 0.0417 - sigmoid_39_loss: 0.0147 - sigmoid_40_loss: 0.0375 - sigmoid_41_loss: 0.0303 - sigmoid_42_loss: 0.0262 - sigmoid_43_loss: 0.0256 - sigmoid_44_loss: 0.0247 - sigmoid_45_loss: 0.0248 - sigmoid_46_loss: 0.0531 - sigmoid_47_loss: 0.0349 - sigmoid_48_loss: 0.0282 - sigmoid_49_loss: 0.0137 - sigmoid_50_loss: 0.0461 - sigmoid_51_loss: 0.0137 - sigmoid_52_loss: 0.0138 - sigmoid_53_loss: 0.0411 - sigmoid_54_loss: 0.0515 - sigmoid_55_loss: 0.0313 - sigmoid_56_loss: 0.0262 - sigmoid_57_loss: 0.0400 - sigmoid_58_loss: 0.0270 - sigmoid_59_loss: 0.0314 - sigmoid_60_loss: 0.0053 - sigmoid_61_loss: 0.0442 - sigmoid_62_loss: 0.0142 - sigmoid_63_loss: 0.0157 - sigmoid_0_acc: 0.9240 - sigmoid_1_acc: 0.9520 - sigmoid_2_acc: 0.9520 - sigmoid_3_acc: 0.9560 - sigmoid_4_acc: 0.9580 - sigmoid_5_acc: 0.9580 - sigmoid_6_acc: 0.9540 - sigmoid_7_acc: 0.9880 - sigmoid_8_acc: 0.9640 - sigmoid_9_acc: 0.9880 - sigmoid_10_acc: 0.9660 - sigmoid_11_acc: 0.9720 - sigmoid_12_acc: 0.9780 - sigmoid_13_acc: 0.9940 - sigmoid_14_acc: 0.9940 - sigmoid_15_acc: 0.9820 - sigmoid_16_acc: 0.9960 - sigmoid_17_acc: 0.9740 - sigmoid_18_acc: 0.9900 - sigmoid_19_acc: 0.9760 - sigmoid_20_acc: 0.9880 - sigmoid_21_acc: 0.9940 - sigmoid_22_acc: 0.9860 - sigmoid_23_acc: 0.9920 - sigmoid_24_acc: 0.9840 - sigmoid_25_acc: 0.9940 - sigmoid_26_acc: 0.9900 - sigmoid_27_acc: 0.9940 - sigmoid_28_acc: 0.9920 - sigmoid_29_acc: 0.9920 - sigmoid_30_acc: 0.9860 - sigmoid_31_acc: 0.9860 - sigmoid_32_acc: 0.9900 - sigmoid_33_acc: 0.9980 - sigmoid_34_acc: 1.0000 - sigmoid_35_acc: 0.9920 - sigmoid_36_acc: 1.0000 - sigmoid_37_acc: 0.9960 - sigmoid_38_acc: 0.9920 - sigmoid_39_acc: 0.9980 - sigmoid_40_acc: 0.9900 - sigmoid_41_acc: 0.9940 - sigmoid_42_acc: 0.9940 - sigmoid_43_acc: 0.9960 - sigmoid_44_acc: 0.9960 - sigmoid_45_acc: 0.9960 - sigmoid_46_acc: 0.9860 - sigmoid_47_acc: 0.9920 - sigmoid_48_acc: 0.9940 - sigmoid_49_acc: 0.9980 - sigmoid_50_acc: 0.9900 - sigmoid_51_acc: 0.9960 - sigmoid_52_acc: 0.9960 - sigmoid_53_acc: 0.9920 - sigmoid_54_acc: 0.9900 - sigmoid_55_acc: 0.9940 - sigmoid_56_acc: 0.9940 - sigmoid_57_acc: 0.9920 - sigmoid_58_acc: 0.9960 - sigmoid_59_acc: 0.9940 - sigmoid_60_acc: 1.0000 - sigmoid_61_acc: 0.9900 - sigmoid_62_acc: 0.9980 - sigmoid_63_acc: 0.9960"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721192/1721192 [==============================] - 3550s 2ms/step - loss: 3.5881 - sigmoid_0_loss: 0.1934 - sigmoid_1_loss: 0.1872 - sigmoid_2_loss: 0.1798 - sigmoid_3_loss: 0.1132 - sigmoid_4_loss: 0.1204 - sigmoid_5_loss: 0.1517 - sigmoid_6_loss: 0.1381 - sigmoid_7_loss: 0.0962 - sigmoid_8_loss: 0.0936 - sigmoid_9_loss: 0.0715 - sigmoid_10_loss: 0.0992 - sigmoid_11_loss: 0.1083 - sigmoid_12_loss: 0.0979 - sigmoid_13_loss: 0.0547 - sigmoid_14_loss: 0.0338 - sigmoid_15_loss: 0.0751 - sigmoid_16_loss: 0.0700 - sigmoid_17_loss: 0.0729 - sigmoid_18_loss: 0.0651 - sigmoid_19_loss: 0.0749 - sigmoid_20_loss: 0.0716 - sigmoid_21_loss: 0.0513 - sigmoid_22_loss: 0.0509 - sigmoid_23_loss: 0.0395 - sigmoid_24_loss: 0.0593 - sigmoid_25_loss: 0.0516 - sigmoid_26_loss: 0.0554 - sigmoid_27_loss: 0.0452 - sigmoid_28_loss: 0.0506 - sigmoid_29_loss: 0.0315 - sigmoid_30_loss: 0.0527 - sigmoid_31_loss: 0.0519 - sigmoid_32_loss: 0.0200 - sigmoid_33_loss: 0.0104 - sigmoid_34_loss: 0.0040 - sigmoid_35_loss: 0.0292 - sigmoid_36_loss: 0.0110 - sigmoid_37_loss: 0.0317 - sigmoid_38_loss: 0.0344 - sigmoid_39_loss: 0.0331 - sigmoid_40_loss: 0.0409 - sigmoid_41_loss: 0.0279 - sigmoid_42_loss: 0.0235 - sigmoid_43_loss: 0.0407 - sigmoid_44_loss: 0.0318 - sigmoid_45_loss: 0.0175 - sigmoid_46_loss: 0.0197 - sigmoid_47_loss: 0.0386 - sigmoid_48_loss: 0.0330 - sigmoid_49_loss: 0.0196 - sigmoid_50_loss: 0.0255 - sigmoid_51_loss: 0.0173 - sigmoid_52_loss: 0.0273 - sigmoid_53_loss: 0.0274 - sigmoid_54_loss: 0.0210 - sigmoid_55_loss: 0.0305 - sigmoid_56_loss: 0.0219 - sigmoid_57_loss: 0.0206 - sigmoid_58_loss: 0.0297 - sigmoid_59_loss: 0.0241 - sigmoid_60_loss: 0.0256 - sigmoid_61_loss: 0.0237 - sigmoid_62_loss: 0.0229 - sigmoid_63_loss: 0.0190 - sigmoid_0_acc: 0.9367 - sigmoid_1_acc: 0.9354 - sigmoid_2_acc: 0.9425 - sigmoid_3_acc: 0.9650 - sigmoid_4_acc: 0.9659 - sigmoid_5_acc: 0.9586 - sigmoid_6_acc: 0.9619 - sigmoid_7_acc: 0.9751 - sigmoid_8_acc: 0.9687 - sigmoid_9_acc: 0.9832 - sigmoid_10_acc: 0.9729 - sigmoid_11_acc: 0.9722 - sigmoid_12_acc: 0.9771 - sigmoid_13_acc: 0.9863 - sigmoid_14_acc: 0.9907 - sigmoid_15_acc: 0.9813 - sigmoid_16_acc: 0.9832 - sigmoid_17_acc: 0.9825 - sigmoid_18_acc: 0.9848 - sigmoid_19_acc: 0.9822 - sigmoid_20_acc: 0.9842 - sigmoid_21_acc: 0.9873 - sigmoid_22_acc: 0.9890 - sigmoid_23_acc: 0.9909 - sigmoid_24_acc: 0.9880 - sigmoid_25_acc: 0.9878 - sigmoid_26_acc: 0.9889 - sigmoid_27_acc: 0.9907 - sigmoid_28_acc: 0.9905 - sigmoid_29_acc: 0.9893 - sigmoid_30_acc: 0.9889 - sigmoid_31_acc: 0.9888 - sigmoid_32_acc: 0.9924 - sigmoid_33_acc: 0.9967 - sigmoid_34_acc: 0.9991 - sigmoid_35_acc: 0.9931 - sigmoid_36_acc: 0.9967 - sigmoid_37_acc: 0.9940 - sigmoid_38_acc: 0.9933 - sigmoid_39_acc: 0.9935 - sigmoid_40_acc: 0.9919 - sigmoid_41_acc: 0.9945 - sigmoid_42_acc: 0.9939 - sigmoid_43_acc: 0.9923 - sigmoid_44_acc: 0.9944 - sigmoid_45_acc: 0.9965 - sigmoid_46_acc: 0.9950 - sigmoid_47_acc: 0.9922 - sigmoid_48_acc: 0.9929 - sigmoid_49_acc: 0.9965 - sigmoid_50_acc: 0.9951 - sigmoid_51_acc: 0.9968 - sigmoid_52_acc: 0.9941 - sigmoid_53_acc: 0.9949 - sigmoid_54_acc: 0.9962 - sigmoid_55_acc: 0.9944 - sigmoid_56_acc: 0.9958 - sigmoid_57_acc: 0.9964 - sigmoid_58_acc: 0.9946 - sigmoid_59_acc: 0.9953 - sigmoid_60_acc: 0.9951 - sigmoid_61_acc: 0.9956 - sigmoid_62_acc: 0.9960 - sigmoid_63_acc: 0.9966 - val_loss: 3.6562 - val_sigmoid_0_loss: 0.1984 - val_sigmoid_1_loss: 0.1891 - val_sigmoid_2_loss: 0.1825 - val_sigmoid_3_loss: 0.1168 - val_sigmoid_4_loss: 0.1232 - val_sigmoid_5_loss: 0.1539 - val_sigmoid_6_loss: 0.1400 - val_sigmoid_7_loss: 0.0971 - val_sigmoid_8_loss: 0.0969 - val_sigmoid_9_loss: 0.0736 - val_sigmoid_10_loss: 0.1014 - val_sigmoid_11_loss: 0.1101 - val_sigmoid_12_loss: 0.0989 - val_sigmoid_13_loss: 0.0560 - val_sigmoid_14_loss: 0.0344 - val_sigmoid_15_loss: 0.0757 - val_sigmoid_16_loss: 0.0721 - val_sigmoid_17_loss: 0.0737 - val_sigmoid_18_loss: 0.0662 - val_sigmoid_19_loss: 0.0765 - val_sigmoid_20_loss: 0.0727 - val_sigmoid_21_loss: 0.0523 - val_sigmoid_22_loss: 0.0515 - val_sigmoid_23_loss: 0.0402 - val_sigmoid_24_loss: 0.0597 - val_sigmoid_25_loss: 0.0524 - val_sigmoid_26_loss: 0.0559 - val_sigmoid_27_loss: 0.0459 - val_sigmoid_28_loss: 0.0505 - val_sigmoid_29_loss: 0.0320 - val_sigmoid_30_loss: 0.0537 - val_sigmoid_31_loss: 0.0524 - val_sigmoid_32_loss: 0.0207 - val_sigmoid_33_loss: 0.0105 - val_sigmoid_34_loss: 0.0040 - val_sigmoid_35_loss: 0.0302 - val_sigmoid_36_loss: 0.0113 - val_sigmoid_37_loss: 0.0324 - val_sigmoid_38_loss: 0.0348 - val_sigmoid_39_loss: 0.0334 - val_sigmoid_40_loss: 0.0413 - val_sigmoid_41_loss: 0.0292 - val_sigmoid_42_loss: 0.0241 - val_sigmoid_43_loss: 0.0410 - val_sigmoid_44_loss: 0.0322 - val_sigmoid_45_loss: 0.0182 - val_sigmoid_46_loss: 0.0202 - val_sigmoid_47_loss: 0.0393 - val_sigmoid_48_loss: 0.0337 - val_sigmoid_49_loss: 0.0205 - val_sigmoid_50_loss: 0.0263 - val_sigmoid_51_loss: 0.0180 - val_sigmoid_52_loss: 0.0281 - val_sigmoid_53_loss: 0.0278 - val_sigmoid_54_loss: 0.0208 - val_sigmoid_55_loss: 0.0311 - val_sigmoid_56_loss: 0.0222 - val_sigmoid_57_loss: 0.0212 - val_sigmoid_58_loss: 0.0299 - val_sigmoid_59_loss: 0.0249 - val_sigmoid_60_loss: 0.0257 - val_sigmoid_61_loss: 0.0239 - val_sigmoid_62_loss: 0.0231 - val_sigmoid_63_loss: 0.0195 - val_sigmoid_0_acc: 0.9362 - val_sigmoid_1_acc: 0.9356 - val_sigmoid_2_acc: 0.9426 - val_sigmoid_3_acc: 0.9648 - val_sigmoid_4_acc: 0.9662 - val_sigmoid_5_acc: 0.9583 - val_sigmoid_6_acc: 0.9619 - val_sigmoid_7_acc: 0.9752 - val_sigmoid_8_acc: 0.9679 - val_sigmoid_9_acc: 0.9833 - val_sigmoid_10_acc: 0.9729 - val_sigmoid_11_acc: 0.9723 - val_sigmoid_12_acc: 0.9771 - val_sigmoid_13_acc: 0.9864 - val_sigmoid_14_acc: 0.9904 - val_sigmoid_15_acc: 0.9815 - val_sigmoid_16_acc: 0.9832 - val_sigmoid_17_acc: 0.9825 - val_sigmoid_18_acc: 0.9849 - val_sigmoid_19_acc: 0.9822 - val_sigmoid_20_acc: 0.9842 - val_sigmoid_21_acc: 0.9872 - val_sigmoid_22_acc: 0.9890 - val_sigmoid_23_acc: 0.9910 - val_sigmoid_24_acc: 0.9880 - val_sigmoid_25_acc: 0.9878 - val_sigmoid_26_acc: 0.9889 - val_sigmoid_27_acc: 0.9908 - val_sigmoid_28_acc: 0.9905 - val_sigmoid_29_acc: 0.9894 - val_sigmoid_30_acc: 0.9890 - val_sigmoid_31_acc: 0.9888 - val_sigmoid_32_acc: 0.9924 - val_sigmoid_33_acc: 0.9968 - val_sigmoid_34_acc: 0.9991 - val_sigmoid_35_acc: 0.9932 - val_sigmoid_36_acc: 0.9966 - val_sigmoid_37_acc: 0.9940 - val_sigmoid_38_acc: 0.9934 - val_sigmoid_39_acc: 0.9936 - val_sigmoid_40_acc: 0.9920 - val_sigmoid_41_acc: 0.9944 - val_sigmoid_42_acc: 0.9938 - val_sigmoid_43_acc: 0.9924 - val_sigmoid_44_acc: 0.9944 - val_sigmoid_45_acc: 0.9965 - val_sigmoid_46_acc: 0.9949 - val_sigmoid_47_acc: 0.9923 - val_sigmoid_48_acc: 0.9930 - val_sigmoid_49_acc: 0.9965 - val_sigmoid_50_acc: 0.9950 - val_sigmoid_51_acc: 0.9968 - val_sigmoid_52_acc: 0.9940 - val_sigmoid_53_acc: 0.9949 - val_sigmoid_54_acc: 0.9962 - val_sigmoid_55_acc: 0.9944 - val_sigmoid_56_acc: 0.9958 - val_sigmoid_57_acc: 0.9964 - val_sigmoid_58_acc: 0.9947 - val_sigmoid_59_acc: 0.9953 - val_sigmoid_60_acc: 0.9951 - val_sigmoid_61_acc: 0.9956 - val_sigmoid_62_acc: 0.9960 - val_sigmoid_63_acc: 0.9966\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    250/1721192 [..............................] - ETA: 1:00:37 - loss: 3.4147 - sigmoid_0_loss: 0.1537 - sigmoid_1_loss: 0.2111 - sigmoid_2_loss: 0.1851 - sigmoid_3_loss: 0.0970 - sigmoid_4_loss: 0.1226 - sigmoid_5_loss: 0.1329 - sigmoid_6_loss: 0.0940 - sigmoid_7_loss: 0.0789 - sigmoid_8_loss: 0.0816 - sigmoid_9_loss: 0.0439 - sigmoid_10_loss: 0.0605 - sigmoid_11_loss: 0.1187 - sigmoid_12_loss: 0.0789 - sigmoid_13_loss: 0.0553 - sigmoid_14_loss: 0.0056 - sigmoid_15_loss: 0.0504 - sigmoid_16_loss: 0.0526 - sigmoid_17_loss: 0.0907 - sigmoid_18_loss: 0.0794 - sigmoid_19_loss: 0.0378 - sigmoid_20_loss: 0.1253 - sigmoid_21_loss: 0.0715 - sigmoid_22_loss: 0.0538 - sigmoid_23_loss: 0.0313 - sigmoid_24_loss: 0.0800 - sigmoid_25_loss: 0.0226 - sigmoid_26_loss: 0.0388 - sigmoid_27_loss: 0.1017 - sigmoid_28_loss: 0.0633 - sigmoid_29_loss: 0.0205 - sigmoid_30_loss: 0.0806 - sigmoid_31_loss: 0.0237 - sigmoid_32_loss: 0.0069 - sigmoid_33_loss: 0.0046 - sigmoid_34_loss: 6.2210e-04 - sigmoid_35_loss: 0.0177 - sigmoid_36_loss: 5.9998e-04 - sigmoid_37_loss: 0.0121 - sigmoid_38_loss: 0.0416 - sigmoid_39_loss: 0.0245 - sigmoid_40_loss: 0.0634 - sigmoid_41_loss: 0.0548 - sigmoid_42_loss: 0.0281 - sigmoid_43_loss: 0.0444 - sigmoid_44_loss: 0.0225 - sigmoid_45_loss: 0.0039 - sigmoid_46_loss: 0.0430 - sigmoid_47_loss: 0.0434 - sigmoid_48_loss: 0.0385 - sigmoid_49_loss: 0.0324 - sigmoid_50_loss: 0.0150 - sigmoid_51_loss: 0.0032 - sigmoid_52_loss: 0.0153 - sigmoid_53_loss: 0.0055 - sigmoid_54_loss: 0.0406 - sigmoid_55_loss: 0.0304 - sigmoid_56_loss: 0.0185 - sigmoid_57_loss: 0.0147 - sigmoid_58_loss: 0.0485 - sigmoid_59_loss: 0.0564 - sigmoid_60_loss: 0.0336 - sigmoid_61_loss: 0.0165 - sigmoid_62_loss: 0.0056 - sigmoid_63_loss: 0.0031 - sigmoid_0_acc: 0.9480 - sigmoid_1_acc: 0.9160 - sigmoid_2_acc: 0.9400 - sigmoid_3_acc: 0.9640 - sigmoid_4_acc: 0.9680 - sigmoid_5_acc: 0.9640 - sigmoid_6_acc: 0.9800 - sigmoid_7_acc: 0.9760 - sigmoid_8_acc: 0.9680 - sigmoid_9_acc: 0.9920 - sigmoid_10_acc: 0.9840 - sigmoid_11_acc: 0.9640 - sigmoid_12_acc: 0.9840 - sigmoid_13_acc: 0.9840 - sigmoid_14_acc: 1.0000 - sigmoid_15_acc: 0.9880 - sigmoid_16_acc: 0.9880 - sigmoid_17_acc: 0.9760 - sigmoid_18_acc: 0.9800 - sigmoid_19_acc: 0.9920 - sigmoid_20_acc: 0.9680 - sigmoid_21_acc: 0.9800 - sigmoid_22_acc: 0.9840 - sigmoid_23_acc: 0.9960 - sigmoid_24_acc: 0.9840 - sigmoid_25_acc: 0.9960 - sigmoid_26_acc: 0.9920 - sigmoid_27_acc: 0.9800 - sigmoid_28_acc: 0.9880 - sigmoid_29_acc: 0.9960 - sigmoid_30_acc: 0.9800 - sigmoid_31_acc: 0.9960 - sigmoid_32_acc: 0.9960 - sigmoid_33_acc: 0.9960 - sigmoid_34_acc: 1.0000 - sigmoid_35_acc: 0.9880 - sigmoid_36_acc: 1.0000 - sigmoid_37_acc: 0.9960 - sigmoid_38_acc: 0.9920 - sigmoid_39_acc: 0.9960 - sigmoid_40_acc: 0.9880 - sigmoid_41_acc: 0.9880 - sigmoid_42_acc: 0.9920 - sigmoid_43_acc: 0.9920 - sigmoid_44_acc: 0.9960 - sigmoid_45_acc: 1.0000 - sigmoid_46_acc: 0.9880 - sigmoid_47_acc: 0.9880 - sigmoid_48_acc: 0.9920 - sigmoid_49_acc: 0.9920 - sigmoid_50_acc: 0.9960 - sigmoid_51_acc: 1.0000 - sigmoid_52_acc: 0.9960 - sigmoid_53_acc: 1.0000 - sigmoid_54_acc: 0.9920 - sigmoid_55_acc: 0.9920 - sigmoid_56_acc: 0.9960 - sigmoid_57_acc: 0.9960 - sigmoid_58_acc: 0.9920 - sigmoid_59_acc: 0.9880 - sigmoid_60_acc: 0.9920 - sigmoid_61_acc: 0.9960 - sigmoid_62_acc: 1.0000 - sigmoid_63_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "    500/1721192 [..............................] - ETA: 56:46 - loss: 3.5104 - sigmoid_0_loss: 0.1548 - sigmoid_1_loss: 0.1961 - sigmoid_2_loss: 0.1810 - sigmoid_3_loss: 0.1199 - sigmoid_4_loss: 0.1212 - sigmoid_5_loss: 0.1813 - sigmoid_6_loss: 0.1161 - sigmoid_7_loss: 0.0915 - sigmoid_8_loss: 0.0926 - sigmoid_9_loss: 0.0466 - sigmoid_10_loss: 0.0984 - sigmoid_11_loss: 0.1071 - sigmoid_12_loss: 0.0749 - sigmoid_13_loss: 0.0535 - sigmoid_14_loss: 0.0066 - sigmoid_15_loss: 0.0592 - sigmoid_16_loss: 0.0541 - sigmoid_17_loss: 0.0631 - sigmoid_18_loss: 0.0935 - sigmoid_19_loss: 0.0492 - sigmoid_20_loss: 0.0759 - sigmoid_21_loss: 0.0445 - sigmoid_22_loss: 0.0475 - sigmoid_23_loss: 0.0398 - sigmoid_24_loss: 0.0759 - sigmoid_25_loss: 0.0160 - sigmoid_26_loss: 0.0643 - sigmoid_27_loss: 0.0886 - sigmoid_28_loss: 0.0962 - sigmoid_29_loss: 0.0149 - sigmoid_30_loss: 0.0454 - sigmoid_31_loss: 0.0236 - sigmoid_32_loss: 0.0101 - sigmoid_33_loss: 0.0058 - sigmoid_34_loss: 5.2979e-04 - sigmoid_35_loss: 0.0183 - sigmoid_36_loss: 6.2862e-04 - sigmoid_37_loss: 0.0278 - sigmoid_38_loss: 0.0566 - sigmoid_39_loss: 0.0314 - sigmoid_40_loss: 0.0413 - sigmoid_41_loss: 0.0416 - sigmoid_42_loss: 0.0313 - sigmoid_43_loss: 0.0347 - sigmoid_44_loss: 0.0247 - sigmoid_45_loss: 0.0087 - sigmoid_46_loss: 0.0300 - sigmoid_47_loss: 0.0423 - sigmoid_48_loss: 0.0368 - sigmoid_49_loss: 0.0258 - sigmoid_50_loss: 0.0431 - sigmoid_51_loss: 0.0049 - sigmoid_52_loss: 0.0182 - sigmoid_53_loss: 0.0140 - sigmoid_54_loss: 0.0223 - sigmoid_55_loss: 0.0552 - sigmoid_56_loss: 0.0274 - sigmoid_57_loss: 0.0151 - sigmoid_58_loss: 0.0452 - sigmoid_59_loss: 0.0477 - sigmoid_60_loss: 0.0350 - sigmoid_61_loss: 0.0174 - sigmoid_62_loss: 0.0189 - sigmoid_63_loss: 0.0032 - sigmoid_0_acc: 0.9480 - sigmoid_1_acc: 0.9300 - sigmoid_2_acc: 0.9380 - sigmoid_3_acc: 0.9620 - sigmoid_4_acc: 0.9680 - sigmoid_5_acc: 0.9500 - sigmoid_6_acc: 0.9680 - sigmoid_7_acc: 0.9760 - sigmoid_8_acc: 0.9640 - sigmoid_9_acc: 0.9900 - sigmoid_10_acc: 0.9720 - sigmoid_11_acc: 0.9700 - sigmoid_12_acc: 0.9860 - sigmoid_13_acc: 0.9860 - sigmoid_14_acc: 1.0000 - sigmoid_15_acc: 0.9860 - sigmoid_16_acc: 0.9860 - sigmoid_17_acc: 0.9840 - sigmoid_18_acc: 0.9760 - sigmoid_19_acc: 0.9900 - sigmoid_20_acc: 0.9820 - sigmoid_21_acc: 0.9880 - sigmoid_22_acc: 0.9860 - sigmoid_23_acc: 0.9940 - sigmoid_24_acc: 0.9840 - sigmoid_25_acc: 0.9980 - sigmoid_26_acc: 0.9860 - sigmoid_27_acc: 0.9820 - sigmoid_28_acc: 0.9800 - sigmoid_29_acc: 0.9980 - sigmoid_30_acc: 0.9900 - sigmoid_31_acc: 0.9960 - sigmoid_32_acc: 0.9940 - sigmoid_33_acc: 0.9960 - sigmoid_34_acc: 1.0000 - sigmoid_35_acc: 0.9920 - sigmoid_36_acc: 1.0000 - sigmoid_37_acc: 0.9940 - sigmoid_38_acc: 0.9900 - sigmoid_39_acc: 0.9940 - sigmoid_40_acc: 0.9920 - sigmoid_41_acc: 0.9920 - sigmoid_42_acc: 0.9920 - sigmoid_43_acc: 0.9940 - sigmoid_44_acc: 0.9960 - sigmoid_45_acc: 0.9980 - sigmoid_46_acc: 0.9920 - sigmoid_47_acc: 0.9900 - sigmoid_48_acc: 0.9920 - sigmoid_49_acc: 0.9940 - sigmoid_50_acc: 0.9900 - sigmoid_51_acc: 0.9980 - sigmoid_52_acc: 0.9940 - sigmoid_53_acc: 0.9980 - sigmoid_54_acc: 0.9960 - sigmoid_55_acc: 0.9860 - sigmoid_56_acc: 0.9940 - sigmoid_57_acc: 0.9960 - sigmoid_58_acc: 0.9920 - sigmoid_59_acc: 0.9900 - sigmoid_60_acc: 0.9900 - sigmoid_61_acc: 0.9960 - sigmoid_62_acc: 0.9980 - sigmoid_63_acc: 1.0000  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721192/1721192 [==============================] - 3626s 2ms/step - loss: 3.5224 - sigmoid_0_loss: 0.1884 - sigmoid_1_loss: 0.1834 - sigmoid_2_loss: 0.1768 - sigmoid_3_loss: 0.1103 - sigmoid_4_loss: 0.1173 - sigmoid_5_loss: 0.1489 - sigmoid_6_loss: 0.1358 - sigmoid_7_loss: 0.0938 - sigmoid_8_loss: 0.0904 - sigmoid_9_loss: 0.0692 - sigmoid_10_loss: 0.0972 - sigmoid_11_loss: 0.1064 - sigmoid_12_loss: 0.0963 - sigmoid_13_loss: 0.0525 - sigmoid_14_loss: 0.0327 - sigmoid_15_loss: 0.0737 - sigmoid_16_loss: 0.0682 - sigmoid_17_loss: 0.0712 - sigmoid_18_loss: 0.0635 - sigmoid_19_loss: 0.0733 - sigmoid_20_loss: 0.0705 - sigmoid_21_loss: 0.0498 - sigmoid_22_loss: 0.0495 - sigmoid_23_loss: 0.0380 - sigmoid_24_loss: 0.0583 - sigmoid_25_loss: 0.0505 - sigmoid_26_loss: 0.0545 - sigmoid_27_loss: 0.0441 - sigmoid_28_loss: 0.0498 - sigmoid_29_loss: 0.0302 - sigmoid_30_loss: 0.0512 - sigmoid_31_loss: 0.0509 - sigmoid_32_loss: 0.0193 - sigmoid_33_loss: 0.0102 - sigmoid_34_loss: 0.0038 - sigmoid_35_loss: 0.0281 - sigmoid_36_loss: 0.0104 - sigmoid_37_loss: 0.0306 - sigmoid_38_loss: 0.0335 - sigmoid_39_loss: 0.0321 - sigmoid_40_loss: 0.0399 - sigmoid_41_loss: 0.0268 - sigmoid_42_loss: 0.0228 - sigmoid_43_loss: 0.0402 - sigmoid_44_loss: 0.0311 - sigmoid_45_loss: 0.0165 - sigmoid_46_loss: 0.0190 - sigmoid_47_loss: 0.0376 - sigmoid_48_loss: 0.0321 - sigmoid_49_loss: 0.0187 - sigmoid_50_loss: 0.0245 - sigmoid_51_loss: 0.0164 - sigmoid_52_loss: 0.0265 - sigmoid_53_loss: 0.0267 - sigmoid_54_loss: 0.0202 - sigmoid_55_loss: 0.0298 - sigmoid_56_loss: 0.0210 - sigmoid_57_loss: 0.0198 - sigmoid_58_loss: 0.0290 - sigmoid_59_loss: 0.0233 - sigmoid_60_loss: 0.0251 - sigmoid_61_loss: 0.0233 - sigmoid_62_loss: 0.0226 - sigmoid_63_loss: 0.0182 - sigmoid_0_acc: 0.9377 - sigmoid_1_acc: 0.9359 - sigmoid_2_acc: 0.9427 - sigmoid_3_acc: 0.9653 - sigmoid_4_acc: 0.9663 - sigmoid_5_acc: 0.9586 - sigmoid_6_acc: 0.9619 - sigmoid_7_acc: 0.9753 - sigmoid_8_acc: 0.9695 - sigmoid_9_acc: 0.9834 - sigmoid_10_acc: 0.9729 - sigmoid_11_acc: 0.9723 - sigmoid_12_acc: 0.9771 - sigmoid_13_acc: 0.9866 - sigmoid_14_acc: 0.9910 - sigmoid_15_acc: 0.9814 - sigmoid_16_acc: 0.9832 - sigmoid_17_acc: 0.9825 - sigmoid_18_acc: 0.9848 - sigmoid_19_acc: 0.9822 - sigmoid_20_acc: 0.9842 - sigmoid_21_acc: 0.9873 - sigmoid_22_acc: 0.9890 - sigmoid_23_acc: 0.9910 - sigmoid_24_acc: 0.9880 - sigmoid_25_acc: 0.9878 - sigmoid_26_acc: 0.9889 - sigmoid_27_acc: 0.9907 - sigmoid_28_acc: 0.9905 - sigmoid_29_acc: 0.9895 - sigmoid_30_acc: 0.9890 - sigmoid_31_acc: 0.9888 - sigmoid_32_acc: 0.9925 - sigmoid_33_acc: 0.9967 - sigmoid_34_acc: 0.9992 - sigmoid_35_acc: 0.9932 - sigmoid_36_acc: 0.9970 - sigmoid_37_acc: 0.9940 - sigmoid_38_acc: 0.9934 - sigmoid_39_acc: 0.9935 - sigmoid_40_acc: 0.9920 - sigmoid_41_acc: 0.9946 - sigmoid_42_acc: 0.9941 - sigmoid_43_acc: 0.9924 - sigmoid_44_acc: 0.9944 - sigmoid_45_acc: 0.9966 - sigmoid_46_acc: 0.9951 - sigmoid_47_acc: 0.9923 - sigmoid_48_acc: 0.9930 - sigmoid_49_acc: 0.9965 - sigmoid_50_acc: 0.9951 - sigmoid_51_acc: 0.9968 - sigmoid_52_acc: 0.9941 - sigmoid_53_acc: 0.9949 - sigmoid_54_acc: 0.9962 - sigmoid_55_acc: 0.9944 - sigmoid_56_acc: 0.9958 - sigmoid_57_acc: 0.9964 - sigmoid_58_acc: 0.9947 - sigmoid_59_acc: 0.9954 - sigmoid_60_acc: 0.9951 - sigmoid_61_acc: 0.9956 - sigmoid_62_acc: 0.9960 - sigmoid_63_acc: 0.9966 - val_loss: 3.6836 - val_sigmoid_0_loss: 0.1990 - val_sigmoid_1_loss: 0.1894 - val_sigmoid_2_loss: 0.1825 - val_sigmoid_3_loss: 0.1169 - val_sigmoid_4_loss: 0.1225 - val_sigmoid_5_loss: 0.1533 - val_sigmoid_6_loss: 0.1403 - val_sigmoid_7_loss: 0.0972 - val_sigmoid_8_loss: 0.0973 - val_sigmoid_9_loss: 0.0737 - val_sigmoid_10_loss: 0.1016 - val_sigmoid_11_loss: 0.1103 - val_sigmoid_12_loss: 0.0993 - val_sigmoid_13_loss: 0.0559 - val_sigmoid_14_loss: 0.0344 - val_sigmoid_15_loss: 0.0758 - val_sigmoid_16_loss: 0.0729 - val_sigmoid_17_loss: 0.0739 - val_sigmoid_18_loss: 0.0663 - val_sigmoid_19_loss: 0.0768 - val_sigmoid_20_loss: 0.0723 - val_sigmoid_21_loss: 0.0531 - val_sigmoid_22_loss: 0.0516 - val_sigmoid_23_loss: 0.0400 - val_sigmoid_24_loss: 0.0602 - val_sigmoid_25_loss: 0.0526 - val_sigmoid_26_loss: 0.0558 - val_sigmoid_27_loss: 0.0460 - val_sigmoid_28_loss: 0.0507 - val_sigmoid_29_loss: 0.0328 - val_sigmoid_30_loss: 0.0540 - val_sigmoid_31_loss: 0.0526 - val_sigmoid_32_loss: 0.0206 - val_sigmoid_33_loss: 0.0105 - val_sigmoid_34_loss: 0.0040 - val_sigmoid_35_loss: 0.0303 - val_sigmoid_36_loss: 0.0113 - val_sigmoid_37_loss: 0.0327 - val_sigmoid_38_loss: 0.0345 - val_sigmoid_39_loss: 0.0331 - val_sigmoid_40_loss: 0.0415 - val_sigmoid_41_loss: 0.0292 - val_sigmoid_42_loss: 0.0241 - val_sigmoid_43_loss: 0.0412 - val_sigmoid_44_loss: 0.0321 - val_sigmoid_45_loss: 0.0183 - val_sigmoid_46_loss: 0.0204 - val_sigmoid_47_loss: 0.0395 - val_sigmoid_48_loss: 0.0337 - val_sigmoid_49_loss: 0.0205 - val_sigmoid_50_loss: 0.0263 - val_sigmoid_51_loss: 0.0182 - val_sigmoid_52_loss: 0.0283 - val_sigmoid_53_loss: 0.0278 - val_sigmoid_54_loss: 0.0210 - val_sigmoid_55_loss: 0.0311 - val_sigmoid_56_loss: 0.0222 - val_sigmoid_57_loss: 0.0213 - val_sigmoid_58_loss: 0.0300 - val_sigmoid_59_loss: 0.0250 - val_sigmoid_60_loss: 0.0257 - val_sigmoid_61_loss: 0.0238 - val_sigmoid_62_loss: 0.0231 - val_sigmoid_63_loss: 0.0194 - val_sigmoid_0_acc: 0.9356 - val_sigmoid_1_acc: 0.9355 - val_sigmoid_2_acc: 0.9426 - val_sigmoid_3_acc: 0.9647 - val_sigmoid_4_acc: 0.9663 - val_sigmoid_5_acc: 0.9586 - val_sigmoid_6_acc: 0.9620 - val_sigmoid_7_acc: 0.9752 - val_sigmoid_8_acc: 0.9680 - val_sigmoid_9_acc: 0.9834 - val_sigmoid_10_acc: 0.9729 - val_sigmoid_11_acc: 0.9722 - val_sigmoid_12_acc: 0.9772 - val_sigmoid_13_acc: 0.9865 - val_sigmoid_14_acc: 0.9905 - val_sigmoid_15_acc: 0.9816 - val_sigmoid_16_acc: 0.9832 - val_sigmoid_17_acc: 0.9825 - val_sigmoid_18_acc: 0.9849 - val_sigmoid_19_acc: 0.9822 - val_sigmoid_20_acc: 0.9842 - val_sigmoid_21_acc: 0.9872 - val_sigmoid_22_acc: 0.9890 - val_sigmoid_23_acc: 0.9911 - val_sigmoid_24_acc: 0.9880 - val_sigmoid_25_acc: 0.9878 - val_sigmoid_26_acc: 0.9889 - val_sigmoid_27_acc: 0.9908 - val_sigmoid_28_acc: 0.9905 - val_sigmoid_29_acc: 0.9894 - val_sigmoid_30_acc: 0.9890 - val_sigmoid_31_acc: 0.9888 - val_sigmoid_32_acc: 0.9923 - val_sigmoid_33_acc: 0.9968 - val_sigmoid_34_acc: 0.9991 - val_sigmoid_35_acc: 0.9931 - val_sigmoid_36_acc: 0.9966 - val_sigmoid_37_acc: 0.9940 - val_sigmoid_38_acc: 0.9935 - val_sigmoid_39_acc: 0.9936 - val_sigmoid_40_acc: 0.9920 - val_sigmoid_41_acc: 0.9944 - val_sigmoid_42_acc: 0.9939 - val_sigmoid_43_acc: 0.9924 - val_sigmoid_44_acc: 0.9944 - val_sigmoid_45_acc: 0.9965 - val_sigmoid_46_acc: 0.9949 - val_sigmoid_47_acc: 0.9923 - val_sigmoid_48_acc: 0.9930 - val_sigmoid_49_acc: 0.9965 - val_sigmoid_50_acc: 0.9951 - val_sigmoid_51_acc: 0.9967 - val_sigmoid_52_acc: 0.9941 - val_sigmoid_53_acc: 0.9949 - val_sigmoid_54_acc: 0.9963 - val_sigmoid_55_acc: 0.9944 - val_sigmoid_56_acc: 0.9958 - val_sigmoid_57_acc: 0.9964 - val_sigmoid_58_acc: 0.9947 - val_sigmoid_59_acc: 0.9954 - val_sigmoid_60_acc: 0.9951 - val_sigmoid_61_acc: 0.9956 - val_sigmoid_62_acc: 0.9960 - val_sigmoid_63_acc: 0.9966\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    250/1721192 [..............................] - ETA: 59:52 - loss: 3.4080 - sigmoid_0_loss: 0.1655 - sigmoid_1_loss: 0.1733 - sigmoid_2_loss: 0.1220 - sigmoid_3_loss: 0.0841 - sigmoid_4_loss: 0.1137 - sigmoid_5_loss: 0.0848 - sigmoid_6_loss: 0.0540 - sigmoid_7_loss: 0.1258 - sigmoid_8_loss: 0.0746 - sigmoid_9_loss: 0.0596 - sigmoid_10_loss: 0.0482 - sigmoid_11_loss: 0.1662 - sigmoid_12_loss: 0.0880 - sigmoid_13_loss: 0.0548 - sigmoid_14_loss: 0.0363 - sigmoid_15_loss: 0.0413 - sigmoid_16_loss: 0.0197 - sigmoid_17_loss: 0.0676 - sigmoid_18_loss: 0.0664 - sigmoid_19_loss: 0.0694 - sigmoid_20_loss: 0.0496 - sigmoid_21_loss: 0.0733 - sigmoid_22_loss: 0.0590 - sigmoid_23_loss: 0.0540 - sigmoid_24_loss: 0.0757 - sigmoid_25_loss: 0.0561 - sigmoid_26_loss: 0.0705 - sigmoid_27_loss: 0.0270 - sigmoid_28_loss: 0.0414 - sigmoid_29_loss: 0.0187 - sigmoid_30_loss: 0.0239 - sigmoid_31_loss: 0.0531 - sigmoid_32_loss: 0.0089 - sigmoid_33_loss: 0.0033 - sigmoid_34_loss: 4.5690e-04 - sigmoid_35_loss: 0.0479 - sigmoid_36_loss: 0.0034 - sigmoid_37_loss: 0.0063 - sigmoid_38_loss: 0.0462 - sigmoid_39_loss: 0.0532 - sigmoid_40_loss: 0.0698 - sigmoid_41_loss: 0.0279 - sigmoid_42_loss: 0.0092 - sigmoid_43_loss: 0.0435 - sigmoid_44_loss: 0.0921 - sigmoid_45_loss: 0.0025 - sigmoid_46_loss: 0.0131 - sigmoid_47_loss: 0.0576 - sigmoid_48_loss: 0.0457 - sigmoid_49_loss: 0.0507 - sigmoid_50_loss: 0.0452 - sigmoid_51_loss: 0.0609 - sigmoid_52_loss: 0.0189 - sigmoid_53_loss: 0.0607 - sigmoid_54_loss: 0.0117 - sigmoid_55_loss: 0.0175 - sigmoid_56_loss: 0.0322 - sigmoid_57_loss: 0.0110 - sigmoid_58_loss: 0.0065 - sigmoid_59_loss: 0.0127 - sigmoid_60_loss: 0.0568 - sigmoid_61_loss: 0.0225 - sigmoid_62_loss: 0.0464 - sigmoid_63_loss: 0.0033 - sigmoid_0_acc: 0.9480 - sigmoid_1_acc: 0.9280 - sigmoid_2_acc: 0.9640 - sigmoid_3_acc: 0.9680 - sigmoid_4_acc: 0.9640 - sigmoid_5_acc: 0.9800 - sigmoid_6_acc: 0.9880 - sigmoid_7_acc: 0.9680 - sigmoid_8_acc: 0.9760 - sigmoid_9_acc: 0.9800 - sigmoid_10_acc: 0.9920 - sigmoid_11_acc: 0.9520 - sigmoid_12_acc: 0.9800 - sigmoid_13_acc: 0.9880 - sigmoid_14_acc: 0.9840 - sigmoid_15_acc: 0.9960 - sigmoid_16_acc: 0.9960 - sigmoid_17_acc: 0.9800 - sigmoid_18_acc: 0.9840 - sigmoid_19_acc: 0.9800 - sigmoid_20_acc: 0.9920 - sigmoid_21_acc: 0.9760 - sigmoid_22_acc: 0.9840 - sigmoid_23_acc: 0.9840 - sigmoid_24_acc: 0.9840 - sigmoid_25_acc: 0.9840 - sigmoid_26_acc: 0.9840 - sigmoid_27_acc: 0.9960 - sigmoid_28_acc: 0.9920 - sigmoid_29_acc: 0.9920 - sigmoid_30_acc: 0.9960 - sigmoid_31_acc: 0.9880 - sigmoid_32_acc: 1.0000 - sigmoid_33_acc: 1.0000 - sigmoid_34_acc: 1.0000 - sigmoid_35_acc: 0.9840 - sigmoid_36_acc: 1.0000 - sigmoid_37_acc: 1.0000 - sigmoid_38_acc: 0.9920 - sigmoid_39_acc: 0.9880 - sigmoid_40_acc: 0.9800 - sigmoid_41_acc: 0.9960 - sigmoid_42_acc: 0.9960 - sigmoid_43_acc: 0.9920 - sigmoid_44_acc: 0.9800 - sigmoid_45_acc: 1.0000 - sigmoid_46_acc: 0.9960 - sigmoid_47_acc: 0.9880 - sigmoid_48_acc: 0.9920 - sigmoid_49_acc: 0.9880 - sigmoid_50_acc: 0.9880 - sigmoid_51_acc: 0.9880 - sigmoid_52_acc: 0.9960 - sigmoid_53_acc: 0.9880 - sigmoid_54_acc: 0.9960 - sigmoid_55_acc: 0.9960 - sigmoid_56_acc: 0.9920 - sigmoid_57_acc: 0.9960 - sigmoid_58_acc: 1.0000 - sigmoid_59_acc: 0.9960 - sigmoid_60_acc: 0.9880 - sigmoid_61_acc: 0.9960 - sigmoid_62_acc: 0.9920 - sigmoid_63_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "    500/1721192 [..............................] - ETA: 57:05 - loss: 3.3260 - sigmoid_0_loss: 0.1599 - sigmoid_1_loss: 0.2313 - sigmoid_2_loss: 0.1239 - sigmoid_3_loss: 0.0911 - sigmoid_4_loss: 0.1069 - sigmoid_5_loss: 0.1229 - sigmoid_6_loss: 0.1184 - sigmoid_7_loss: 0.0931 - sigmoid_8_loss: 0.0855 - sigmoid_9_loss: 0.0703 - sigmoid_10_loss: 0.0701 - sigmoid_11_loss: 0.1362 - sigmoid_12_loss: 0.0923 - sigmoid_13_loss: 0.0485 - sigmoid_14_loss: 0.0258 - sigmoid_15_loss: 0.0381 - sigmoid_16_loss: 0.0294 - sigmoid_17_loss: 0.0540 - sigmoid_18_loss: 0.0506 - sigmoid_19_loss: 0.0545 - sigmoid_20_loss: 0.0495 - sigmoid_21_loss: 0.0648 - sigmoid_22_loss: 0.0622 - sigmoid_23_loss: 0.0425 - sigmoid_24_loss: 0.0494 - sigmoid_25_loss: 0.0488 - sigmoid_26_loss: 0.0592 - sigmoid_27_loss: 0.0463 - sigmoid_28_loss: 0.0400 - sigmoid_29_loss: 0.0194 - sigmoid_30_loss: 0.0257 - sigmoid_31_loss: 0.0535 - sigmoid_32_loss: 0.0150 - sigmoid_33_loss: 0.0098 - sigmoid_34_loss: 0.0027 - sigmoid_35_loss: 0.0343 - sigmoid_36_loss: 0.0033 - sigmoid_37_loss: 0.0282 - sigmoid_38_loss: 0.0264 - sigmoid_39_loss: 0.0384 - sigmoid_40_loss: 0.0530 - sigmoid_41_loss: 0.0202 - sigmoid_42_loss: 0.0329 - sigmoid_43_loss: 0.0259 - sigmoid_44_loss: 0.0559 - sigmoid_45_loss: 0.0085 - sigmoid_46_loss: 0.0307 - sigmoid_47_loss: 0.0408 - sigmoid_48_loss: 0.0330 - sigmoid_49_loss: 0.0278 - sigmoid_50_loss: 0.0344 - sigmoid_51_loss: 0.0394 - sigmoid_52_loss: 0.0159 - sigmoid_53_loss: 0.0387 - sigmoid_54_loss: 0.0427 - sigmoid_55_loss: 0.0280 - sigmoid_56_loss: 0.0181 - sigmoid_57_loss: 0.0074 - sigmoid_58_loss: 0.0106 - sigmoid_59_loss: 0.0104 - sigmoid_60_loss: 0.0468 - sigmoid_61_loss: 0.0134 - sigmoid_62_loss: 0.0253 - sigmoid_63_loss: 0.0421 - sigmoid_0_acc: 0.9480 - sigmoid_1_acc: 0.9060 - sigmoid_2_acc: 0.9600 - sigmoid_3_acc: 0.9680 - sigmoid_4_acc: 0.9660 - sigmoid_5_acc: 0.9660 - sigmoid_6_acc: 0.9620 - sigmoid_7_acc: 0.9760 - sigmoid_8_acc: 0.9720 - sigmoid_9_acc: 0.9780 - sigmoid_10_acc: 0.9820 - sigmoid_11_acc: 0.9640 - sigmoid_12_acc: 0.9800 - sigmoid_13_acc: 0.9880 - sigmoid_14_acc: 0.9900 - sigmoid_15_acc: 0.9940 - sigmoid_16_acc: 0.9920 - sigmoid_17_acc: 0.9860 - sigmoid_18_acc: 0.9880 - sigmoid_19_acc: 0.9860 - sigmoid_20_acc: 0.9880 - sigmoid_21_acc: 0.9800 - sigmoid_22_acc: 0.9840 - sigmoid_23_acc: 0.9880 - sigmoid_24_acc: 0.9900 - sigmoid_25_acc: 0.9860 - sigmoid_26_acc: 0.9860 - sigmoid_27_acc: 0.9920 - sigmoid_28_acc: 0.9920 - sigmoid_29_acc: 0.9940 - sigmoid_30_acc: 0.9960 - sigmoid_31_acc: 0.9900 - sigmoid_32_acc: 0.9960 - sigmoid_33_acc: 0.9980 - sigmoid_34_acc: 0.9980 - sigmoid_35_acc: 0.9880 - sigmoid_36_acc: 1.0000 - sigmoid_37_acc: 0.9940 - sigmoid_38_acc: 0.9960 - sigmoid_39_acc: 0.9920 - sigmoid_40_acc: 0.9860 - sigmoid_41_acc: 0.9960 - sigmoid_42_acc: 0.9900 - sigmoid_43_acc: 0.9960 - sigmoid_44_acc: 0.9880 - sigmoid_45_acc: 0.9980 - sigmoid_46_acc: 0.9920 - sigmoid_47_acc: 0.9920 - sigmoid_48_acc: 0.9940 - sigmoid_49_acc: 0.9940 - sigmoid_50_acc: 0.9920 - sigmoid_51_acc: 0.9920 - sigmoid_52_acc: 0.9960 - sigmoid_53_acc: 0.9920 - sigmoid_54_acc: 0.9920 - sigmoid_55_acc: 0.9940 - sigmoid_56_acc: 0.9960 - sigmoid_57_acc: 0.9980 - sigmoid_58_acc: 0.9980 - sigmoid_59_acc: 0.9980 - sigmoid_60_acc: 0.9900 - sigmoid_61_acc: 0.9980 - sigmoid_62_acc: 0.9960 - sigmoid_63_acc: 0.9920    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721192/1721192 [==============================] - 3690s 2ms/step - loss: 3.4497 - sigmoid_0_loss: 0.1835 - sigmoid_1_loss: 0.1797 - sigmoid_2_loss: 0.1734 - sigmoid_3_loss: 0.1072 - sigmoid_4_loss: 0.1140 - sigmoid_5_loss: 0.1458 - sigmoid_6_loss: 0.1330 - sigmoid_7_loss: 0.0912 - sigmoid_8_loss: 0.0871 - sigmoid_9_loss: 0.0667 - sigmoid_10_loss: 0.0946 - sigmoid_11_loss: 0.1043 - sigmoid_12_loss: 0.0943 - sigmoid_13_loss: 0.0504 - sigmoid_14_loss: 0.0317 - sigmoid_15_loss: 0.0720 - sigmoid_16_loss: 0.0661 - sigmoid_17_loss: 0.0692 - sigmoid_18_loss: 0.0618 - sigmoid_19_loss: 0.0714 - sigmoid_20_loss: 0.0694 - sigmoid_21_loss: 0.0483 - sigmoid_22_loss: 0.0479 - sigmoid_23_loss: 0.0366 - sigmoid_24_loss: 0.0569 - sigmoid_25_loss: 0.0491 - sigmoid_26_loss: 0.0535 - sigmoid_27_loss: 0.0428 - sigmoid_28_loss: 0.0486 - sigmoid_29_loss: 0.0291 - sigmoid_30_loss: 0.0498 - sigmoid_31_loss: 0.0496 - sigmoid_32_loss: 0.0186 - sigmoid_33_loss: 0.0100 - sigmoid_34_loss: 0.0035 - sigmoid_35_loss: 0.0269 - sigmoid_36_loss: 0.0100 - sigmoid_37_loss: 0.0291 - sigmoid_38_loss: 0.0325 - sigmoid_39_loss: 0.0310 - sigmoid_40_loss: 0.0389 - sigmoid_41_loss: 0.0257 - sigmoid_42_loss: 0.0221 - sigmoid_43_loss: 0.0395 - sigmoid_44_loss: 0.0303 - sigmoid_45_loss: 0.0154 - sigmoid_46_loss: 0.0184 - sigmoid_47_loss: 0.0365 - sigmoid_48_loss: 0.0310 - sigmoid_49_loss: 0.0178 - sigmoid_50_loss: 0.0234 - sigmoid_51_loss: 0.0156 - sigmoid_52_loss: 0.0255 - sigmoid_53_loss: 0.0261 - sigmoid_54_loss: 0.0195 - sigmoid_55_loss: 0.0288 - sigmoid_56_loss: 0.0202 - sigmoid_57_loss: 0.0189 - sigmoid_58_loss: 0.0282 - sigmoid_59_loss: 0.0224 - sigmoid_60_loss: 0.0245 - sigmoid_61_loss: 0.0228 - sigmoid_62_loss: 0.0221 - sigmoid_63_loss: 0.0176 - sigmoid_0_acc: 0.9387 - sigmoid_1_acc: 0.9367 - sigmoid_2_acc: 0.9430 - sigmoid_3_acc: 0.9657 - sigmoid_4_acc: 0.9667 - sigmoid_5_acc: 0.9587 - sigmoid_6_acc: 0.9620 - sigmoid_7_acc: 0.9755 - sigmoid_8_acc: 0.9704 - sigmoid_9_acc: 0.9836 - sigmoid_10_acc: 0.9730 - sigmoid_11_acc: 0.9723 - sigmoid_12_acc: 0.9771 - sigmoid_13_acc: 0.9869 - sigmoid_14_acc: 0.9911 - sigmoid_15_acc: 0.9814 - sigmoid_16_acc: 0.9833 - sigmoid_17_acc: 0.9826 - sigmoid_18_acc: 0.9849 - sigmoid_19_acc: 0.9822 - sigmoid_20_acc: 0.9842 - sigmoid_21_acc: 0.9874 - sigmoid_22_acc: 0.9890 - sigmoid_23_acc: 0.9911 - sigmoid_24_acc: 0.9880 - sigmoid_25_acc: 0.9878 - sigmoid_26_acc: 0.9889 - sigmoid_27_acc: 0.9907 - sigmoid_28_acc: 0.9905 - sigmoid_29_acc: 0.9898 - sigmoid_30_acc: 0.9890 - sigmoid_31_acc: 0.9888 - sigmoid_32_acc: 0.9927 - sigmoid_33_acc: 0.9967 - sigmoid_34_acc: 0.9992 - sigmoid_35_acc: 0.9933 - sigmoid_36_acc: 0.9971 - sigmoid_37_acc: 0.9940 - sigmoid_38_acc: 0.9934 - sigmoid_39_acc: 0.9936 - sigmoid_40_acc: 0.9920 - sigmoid_41_acc: 0.9946 - sigmoid_42_acc: 0.9942 - sigmoid_43_acc: 0.9924 - sigmoid_44_acc: 0.9944 - sigmoid_45_acc: 0.9967 - sigmoid_46_acc: 0.9953 - sigmoid_47_acc: 0.9922 - sigmoid_48_acc: 0.9930 - sigmoid_49_acc: 0.9965 - sigmoid_50_acc: 0.9952 - sigmoid_51_acc: 0.9969 - sigmoid_52_acc: 0.9941 - sigmoid_53_acc: 0.9949 - sigmoid_54_acc: 0.9962 - sigmoid_55_acc: 0.9944 - sigmoid_56_acc: 0.9958 - sigmoid_57_acc: 0.9964 - sigmoid_58_acc: 0.9947 - sigmoid_59_acc: 0.9954 - sigmoid_60_acc: 0.9951 - sigmoid_61_acc: 0.9956 - sigmoid_62_acc: 0.9960 - sigmoid_63_acc: 0.9966 - val_loss: 3.7264 - val_sigmoid_0_loss: 0.1995 - val_sigmoid_1_loss: 0.1908 - val_sigmoid_2_loss: 0.1831 - val_sigmoid_3_loss: 0.1175 - val_sigmoid_4_loss: 0.1229 - val_sigmoid_5_loss: 0.1539 - val_sigmoid_6_loss: 0.1415 - val_sigmoid_7_loss: 0.0979 - val_sigmoid_8_loss: 0.0985 - val_sigmoid_9_loss: 0.0745 - val_sigmoid_10_loss: 0.1025 - val_sigmoid_11_loss: 0.1110 - val_sigmoid_12_loss: 0.1001 - val_sigmoid_13_loss: 0.0559 - val_sigmoid_14_loss: 0.0349 - val_sigmoid_15_loss: 0.0765 - val_sigmoid_16_loss: 0.0731 - val_sigmoid_17_loss: 0.0745 - val_sigmoid_18_loss: 0.0668 - val_sigmoid_19_loss: 0.0773 - val_sigmoid_20_loss: 0.0725 - val_sigmoid_21_loss: 0.0528 - val_sigmoid_22_loss: 0.0523 - val_sigmoid_23_loss: 0.0403 - val_sigmoid_24_loss: 0.0602 - val_sigmoid_25_loss: 0.0529 - val_sigmoid_26_loss: 0.0561 - val_sigmoid_27_loss: 0.0461 - val_sigmoid_28_loss: 0.0508 - val_sigmoid_29_loss: 0.0324 - val_sigmoid_30_loss: 0.0544 - val_sigmoid_31_loss: 0.0531 - val_sigmoid_32_loss: 0.0210 - val_sigmoid_33_loss: 0.0107 - val_sigmoid_34_loss: 0.0040 - val_sigmoid_35_loss: 0.0306 - val_sigmoid_36_loss: 0.0116 - val_sigmoid_37_loss: 0.0330 - val_sigmoid_38_loss: 0.0346 - val_sigmoid_39_loss: 0.0333 - val_sigmoid_40_loss: 0.0417 - val_sigmoid_41_loss: 0.0293 - val_sigmoid_42_loss: 0.0242 - val_sigmoid_43_loss: 0.0412 - val_sigmoid_44_loss: 0.0325 - val_sigmoid_45_loss: 0.0185 - val_sigmoid_46_loss: 0.0204 - val_sigmoid_47_loss: 0.0399 - val_sigmoid_48_loss: 0.0340 - val_sigmoid_49_loss: 0.0208 - val_sigmoid_50_loss: 0.0263 - val_sigmoid_51_loss: 0.0182 - val_sigmoid_52_loss: 0.0285 - val_sigmoid_53_loss: 0.0281 - val_sigmoid_54_loss: 0.0209 - val_sigmoid_55_loss: 0.0314 - val_sigmoid_56_loss: 0.0222 - val_sigmoid_57_loss: 0.0215 - val_sigmoid_58_loss: 0.0302 - val_sigmoid_59_loss: 0.0251 - val_sigmoid_60_loss: 0.0259 - val_sigmoid_61_loss: 0.0239 - val_sigmoid_62_loss: 0.0232 - val_sigmoid_63_loss: 0.0194 - val_sigmoid_0_acc: 0.9357 - val_sigmoid_1_acc: 0.9350 - val_sigmoid_2_acc: 0.9425 - val_sigmoid_3_acc: 0.9648 - val_sigmoid_4_acc: 0.9663 - val_sigmoid_5_acc: 0.9585 - val_sigmoid_6_acc: 0.9619 - val_sigmoid_7_acc: 0.9751 - val_sigmoid_8_acc: 0.9677 - val_sigmoid_9_acc: 0.9832 - val_sigmoid_10_acc: 0.9729 - val_sigmoid_11_acc: 0.9722 - val_sigmoid_12_acc: 0.9772 - val_sigmoid_13_acc: 0.9865 - val_sigmoid_14_acc: 0.9905 - val_sigmoid_15_acc: 0.9815 - val_sigmoid_16_acc: 0.9832 - val_sigmoid_17_acc: 0.9825 - val_sigmoid_18_acc: 0.9849 - val_sigmoid_19_acc: 0.9822 - val_sigmoid_20_acc: 0.9842 - val_sigmoid_21_acc: 0.9872 - val_sigmoid_22_acc: 0.9890 - val_sigmoid_23_acc: 0.9911 - val_sigmoid_24_acc: 0.9880 - val_sigmoid_25_acc: 0.9879 - val_sigmoid_26_acc: 0.9889 - val_sigmoid_27_acc: 0.9908 - val_sigmoid_28_acc: 0.9905 - val_sigmoid_29_acc: 0.9894 - val_sigmoid_30_acc: 0.9889 - val_sigmoid_31_acc: 0.9888 - val_sigmoid_32_acc: 0.9924 - val_sigmoid_33_acc: 0.9968 - val_sigmoid_34_acc: 0.9991 - val_sigmoid_35_acc: 0.9931 - val_sigmoid_36_acc: 0.9966 - val_sigmoid_37_acc: 0.9940 - val_sigmoid_38_acc: 0.9935 - val_sigmoid_39_acc: 0.9936 - val_sigmoid_40_acc: 0.9920 - val_sigmoid_41_acc: 0.9944 - val_sigmoid_42_acc: 0.9939 - val_sigmoid_43_acc: 0.9924 - val_sigmoid_44_acc: 0.9944 - val_sigmoid_45_acc: 0.9966 - val_sigmoid_46_acc: 0.9949 - val_sigmoid_47_acc: 0.9923 - val_sigmoid_48_acc: 0.9930 - val_sigmoid_49_acc: 0.9965 - val_sigmoid_50_acc: 0.9951 - val_sigmoid_51_acc: 0.9967 - val_sigmoid_52_acc: 0.9941 - val_sigmoid_53_acc: 0.9949 - val_sigmoid_54_acc: 0.9963 - val_sigmoid_55_acc: 0.9944 - val_sigmoid_56_acc: 0.9958 - val_sigmoid_57_acc: 0.9964 - val_sigmoid_58_acc: 0.9947 - val_sigmoid_59_acc: 0.9953 - val_sigmoid_60_acc: 0.9951 - val_sigmoid_61_acc: 0.9956 - val_sigmoid_62_acc: 0.9960 - val_sigmoid_63_acc: 0.9965\n",
      "0.2366327890991568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99  15490755\n",
      "         1.0       0.80      0.14      0.24    245885\n",
      "\n",
      "    accuracy                           0.99  15736640\n",
      "   macro avg       0.89      0.57      0.61  15736640\n",
      "weighted avg       0.98      0.99      0.98  15736640\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.99      1.00      0.99  15490755\n",
      "                  0.88      0.31      0.46     21680\n",
      "                  0.64      0.14      0.23     17030\n",
      "                  0.84      0.13      0.22     15699\n",
      "                  0.76      0.16      0.26      9767\n",
      "                  0.86      0.20      0.32      9994\n",
      "                  0.85      0.04      0.07     10480\n",
      "                  0.56      0.01      0.02      9401\n",
      "                  0.71      0.09      0.16      6472\n",
      "                  0.52      0.16      0.24      8166\n",
      "                  0.89      0.24      0.38      5328\n",
      "                  0.69      0.01      0.01      6692\n",
      "                  0.45      0.00      0.01      6825\n",
      "                  0.92      0.02      0.04      5737\n",
      "                  0.87      0.32      0.47      4599\n",
      "                  0.82      0.62      0.71      4695\n",
      "                  0.97      0.22      0.36      5818\n",
      "                  0.65      0.03      0.06      4187\n",
      "                  0.60      0.02      0.03      4313\n",
      "                  0.85      0.04      0.08      3868\n",
      "                  0.59      0.01      0.02      4404\n",
      "                  1.00      0.00      0.00      3880\n",
      "                  0.55      0.04      0.07      3147\n",
      "                  0.93      0.04      0.07      2793\n",
      "                  0.86      0.21      0.34      2652\n",
      "                  0.99      0.09      0.16      3215\n",
      "                  0.91      0.06      0.12      3170\n",
      "                  1.00      0.00      0.00      2739\n",
      "                  0.75      0.04      0.07      2342\n",
      "                  1.00      0.13      0.23      2686\n",
      "                  0.70      0.18      0.29      2881\n",
      "                  0.80      0.02      0.05      2754\n",
      "                  0.78      0.01      0.01      2760\n",
      "                  0.66      0.29      0.41      2165\n",
      "                  0.98      0.13      0.23       900\n",
      "                  0.95      0.82      0.88       990\n",
      "                  0.72      0.17      0.28      1910\n",
      "                  0.77      0.67      0.72      1660\n",
      "                  0.97      0.23      0.37      1876\n",
      "                  0.94      0.10      0.18      1733\n",
      "                  0.76      0.13      0.23      1727\n",
      "                  0.66      0.04      0.07      2033\n",
      "                  0.78      0.19      0.30      1574\n",
      "                  0.67      0.26      0.38      1760\n",
      "                  0.75      0.00      0.01      1884\n",
      "                  0.97      0.08      0.14      1496\n",
      "                  0.78      0.21      0.33      1013\n",
      "                  0.72      0.34      0.47      1579\n",
      "                  0.80      0.01      0.02      1907\n",
      "                  0.57      0.02      0.04      1736\n",
      "                  0.98      0.44      0.61      1509\n",
      "                  0.62      0.06      0.11      1257\n",
      "                  0.89      0.32      0.47      1079\n",
      "                  0.60      0.03      0.06      1465\n",
      "                  0.88      0.01      0.02      1262\n",
      "                  0.79      0.04      0.08       955\n",
      "                  0.93      0.03      0.06      1403\n",
      "                  0.71      0.08      0.14      1073\n",
      "                  0.96      0.19      0.32      1101\n",
      "                  0.47      0.01      0.01      1314\n",
      "                  0.61      0.09      0.16      1182\n",
      "                  0.75      0.00      0.00      1205\n",
      "                  1.00      0.00      0.01      1080\n",
      "                  1.00      0.04      0.09      1032\n",
      "                  0.54      0.04      0.08       851\n",
      "\n",
      "    accuracy                           0.99  15736640\n",
      "   macro avg       0.79      0.15      0.21  15736640\n",
      "weighted avg       0.98      0.99      0.98  15736640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(data_dir)\n",
    "wv_path = (data_dir / \"{:s}_wv.npy\".format(lang)).__str__()\n",
    "X_path = (data_dir / \"{:s}_X.npy\".format(lang)).__str__()\n",
    "y_path = (data_dir / \"{:s}_y.npy\".format(lang)).__str__()\n",
    "emoji_path = (data_dir / \"{:s}_emoji.txt\".format(lang)).__str__()\n",
    "\n",
    "wv = np.load(wv_path, allow_pickle=True)\n",
    "input_vec = np.load(X_path, allow_pickle=True)\n",
    "input_label = np.load(y_path, allow_pickle=True)\n",
    "\n",
    "nb_tokens = len(wv)\n",
    "embed_dim = wv.shape[1]\n",
    "input_len = len(input_label)\n",
    "nb_classes = input_label.shape[1]\n",
    "maxlen = input_vec.shape[1]\n",
    "\n",
    "train_end = int(input_len*0.7)\n",
    "val_end = int(input_len*0.9)\n",
    "\n",
    "(X_train, y_train) = (input_vec[:train_end], input_label[:train_end])\n",
    "(X_val, y_val) = (input_vec[train_end:val_end], input_label[train_end:val_end])\n",
    "(X_test, y_test) = (input_vec[val_end:], input_label[val_end:])\n",
    "\n",
    "if multilabel:\n",
    "    def to_multilabel(y):\n",
    "        outputs = []\n",
    "        for i in range(nb_classes):\n",
    "            outputs.append(y[:, i])\n",
    "        return outputs\n",
    "\n",
    "    y_train = to_multilabel(y_train)\n",
    "    y_val = to_multilabel(y_val)\n",
    "    y_test = to_multilabel(y_test)\n",
    "\n",
    "model = elsa_architecture(nb_classes=nb_classes,\n",
    "                          nb_tokens=nb_tokens,\n",
    "                          maxlen=maxlen,\n",
    "                          final_dropout_rate=final_drop,\n",
    "                          embed_dropout_rate=embed_drop,\n",
    "                          load_embedding=True,\n",
    "                          pre_embedding=wv,\n",
    "                          high=highway,\n",
    "                          embed_dim=embed_dim,\n",
    "                          multilabel=multilabel)\n",
    "model.summary()\n",
    "\n",
    "computed_class_weight = None\n",
    "\n",
    "if multilabel:\n",
    "    loss = \"binary_crossentropy\"\n",
    "else:\n",
    "    loss = \"categorical_crossentropy\"\n",
    "    if compute_class_weight:\n",
    "        y_train_sps = []\n",
    "        for row in y_train:\n",
    "            y_train_sps.extend(np.where(row)[0].tolist())\n",
    "        computed_class_weight = class_weight.compute_class_weight(\n",
    "            'balanced', list(range(nb_classes)), y_train_sps)\n",
    "        print(\"computed class weight = {:s}\".format(str(computed_class_weight)))\n",
    "\n",
    "if optimizer == 'adam':\n",
    "    adam = Adam(clipnorm=1, lr=lr)\n",
    "    model.compile(loss=loss, optimizer=adam, metrics=['accuracy'])\n",
    "elif optimizer == 'rmsprop':\n",
    "    model.compile(loss=loss, optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "checkpoint_dir = Path(checkpoint_dir)\n",
    "if not checkpoint_dir.exists():\n",
    "    checkpoint_dir.mkdir()\n",
    "checkpoint_weight_path = (checkpoint_dir / \"elsa_{:s}.hdf5\".format(lang)).__str__()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto'),\n",
    "    keras.callbacks.ModelCheckpoint(checkpoint_weight_path, monitor='val_loss',\n",
    "                                    verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "]\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_val, y_val),\n",
    "          class_weight=computed_class_weight,\n",
    "          callbacks=callbacks,\n",
    "          verbose=1)\n",
    "\n",
    "freq = {line.split()[0]: int(line.split()[1]) for line in open(emoji_path).readlines()}\n",
    "freq_topn = sorted(freq.items(), key=itemgetter(1), reverse=True)[:nb_classes]\n",
    "\n",
    "if multilabel:\n",
    "    y_pred = model.predict([X_test], batch_size=batch_size)\n",
    "    y_pred = [np.squeeze(p) for p in y_pred]\n",
    "\n",
    "    y_test_1d = np.array(y_test).flatten()\n",
    "    y_pred_1d = np.array(y_pred).flatten()\n",
    "    print(f1_score(y_test_1d, y_pred_1d > 0.5))\n",
    "    print(classification_report(y_test_1d, y_pred_1d > 0.5))\n",
    "\n",
    "    gold, pred = [], []\n",
    "    for i in range(len(X_test)):\n",
    "        each_gold, each_pred = [], []\n",
    "        for c in range(nb_classes):\n",
    "            if y_test[c][i] == 1.0:\n",
    "                each_gold.append(c+1)\n",
    "            else:\n",
    "                each_gold.append(0)\n",
    "            if y_pred[c][i] > 0.5:\n",
    "                each_pred.append(c+1)\n",
    "            else:\n",
    "                each_pred.append(0)\n",
    "        gold.extend(each_gold)\n",
    "        pred.extend(each_pred)\n",
    "\n",
    "    target_name = [\"\"] + [e[0] for e in freq_topn]\n",
    "    print(classification_report(gold, pred, target_names=target_name))\n",
    "else:\n",
    "    _, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "    print(acc)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test.argmax(axis=1), y_pred.argmax(\n",
    "        axis=1), target_names=[e[0] for e in freq_topn]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
