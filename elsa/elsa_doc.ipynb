{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from attlayer import AttentionWeightedAverage\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elsa_doc_model(hidden_dim = 64, dropout = 0.5, mode = 'train'):\n",
    "    I_en = Input(shape=(nb_maxlen[0], nb_feature[1]), dtype='float32')\n",
    "    en_out = AttentionWeightedAverage()(I_en)\n",
    "    I_ot = Input(shape=(nb_maxlen[1], nb_feature[0]), dtype='float32')\n",
    "    jp_out = AttentionWeightedAverage()(I_ot)\n",
    "    O_to = concatenate([jp_out, en_out])\n",
    "    O_to = Dense(hidden_dim, activation='selu')(O_to)\n",
    "    if mode == 'train':\n",
    "        O_to = Dropout(dropout)(O_to)\n",
    "    O_out = Dense(1, activation='sigmoid', name='softmax')(O_to)\n",
    "    model = Model(inputs=[I_ot, I_en], outputs=O_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "cur_lan = \"de\"\n",
    "cur_cat = \"_music\"\n",
    "cur_test = \"en_{:s}/\".format(cur_lan)\n",
    "#nb_feature = [2348, 2304] # embedding shape for other language and english, please do not change\n",
    "nb_feature = [2248, 2248] # embedding shape for other language and english, please do not change\n",
    "nb_maxlen = [20, 20] # max number of sentences in document\n",
    "label_path = \"../dataset/Amazon review/\"\n",
    "embed_path = \"./embed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigh_path = \"./ckpt/elsa_doc_{:s}_{:s}.hdf5\".format(cur_cat[1:], cur_test[-3:-1])\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "hidden_dim = 64\n",
    "dropout = 0.5\n",
    "\n",
    "mode = \"train\"\n",
    "train_chose = True\n",
    "pretrained_path = \"./ckpt/elsa_doc_{:s}_{:s}.hdf5\".format(cur_cat[1:], cur_test[-3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_test_review en_music_test_review (2000, 20, 2248) (20, 2248)\n",
      "en_train_review en_music_train_review (2000, 20, 2248) (20, 2248)\n",
      "de_test_review de_music_test_review (2000, 20, 2248) (20, 2248)\n",
      "de_train_review de_music_train_review (2000, 20, 2248) (20, 2248)\n"
     ]
    }
   ],
   "source": [
    "labes = {\"en_test_review\":[],\n",
    "         \"en_train_review\":[], \n",
    "         cur_test[-3:-1]+\"_test_review\":[],\n",
    "         cur_test[-3:-1]+\"_train_review\":[]}\n",
    "\n",
    "tags = [\"en_test_review\",\n",
    "        \"en_train_review\",\n",
    "        cur_test[-3:-1]+\"_test_review\",\n",
    "        cur_test[-3:-1]+\"_train_review\"]\n",
    "\n",
    "filename = [label_path+cur_test+\"en/\"+cur_cat[1:]+\"_test_review.tsv\",\n",
    "            label_path+cur_test+\"en/\"+cur_cat[1:]+\"_train_review.tsv\",\n",
    "            label_path+cur_test+cur_test[-3:]+cur_cat[1:]+\"_test_review.tsv\",\n",
    "            label_path+cur_test+cur_test[-3:]+cur_cat[1:]+\"_train_review.tsv\"]\n",
    "\n",
    "for i, file in enumerate(filename):\n",
    "    data = open(file, \"r\")\n",
    "    for line in data:\n",
    "        tmp_data = line.strip().split(\"\\t\")\n",
    "        rating = int(tmp_data[0])\n",
    "        if rating > 3:\n",
    "            labes[tags[i]].append(1)\n",
    "        else:\n",
    "            labes[tags[i]].append(0)\n",
    "    data.close()\n",
    "\n",
    "# tidy elsa_embedding\n",
    "elsa_embedding = {x:[np.array([]), np.array([])] for x in tags}\n",
    "\n",
    "def roundup(x):\n",
    "    import math\n",
    "    return int(math.ceil(x / 10.0)) * 10\n",
    "\n",
    "for tag in tags:\n",
    "    tmp_tag = tag[:2] + cur_cat + tag[2:]\n",
    "    vec = np.load(embed_path+cur_test+ cur_test[-3:]+tmp_tag+\"_embed.npz.npy\", allow_pickle=True)\n",
    "    vec = sequence.pad_sequences(vec, dtype=np.float32, maxlen=nb_maxlen[0])\n",
    "    elsa_embedding[tag][0] = vec   \n",
    "\n",
    "for tag in tags:\n",
    "    tmp_tag = tag[:2] + cur_cat + tag[2:]\n",
    "    vec = np.load(embed_path+cur_test+\"en/\"+tmp_tag+\"_embed.npz.npy\", allow_pickle=True)\n",
    "    vec = sequence.pad_sequences(vec, dtype=np.float32, maxlen=nb_maxlen[1])\n",
    "    elsa_embedding[tag][1] = np.array(vec)\n",
    "    print(tag, tmp_tag, vec.shape, vec[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 20, 2248)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 20, 2248)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_2 (A (None, 2248)         2248        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_1 (A (None, 2248)         2248        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4496)         0           attention_weighted_average_2[0][0\n",
      "                                                                 attention_weighted_average_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           287808      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 292,369\n",
      "Trainable params: 292,369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train elsa_doc model\n",
    "elsa_doc = elsa_doc_model( hidden_dim=hidden_dim, dropout=dropout, mode=mode )\n",
    "elsa_doc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.6669 - acc: 0.6315 - val_loss: 0.6512 - val_acc: 0.6420\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 0.6217 - acc: 0.6725 - val_loss: 0.7116 - val_acc: 0.6380\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 1s 551us/step - loss: 0.6072 - acc: 0.6890 - val_loss: 0.6764 - val_acc: 0.6605\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 1s 542us/step - loss: 0.6014 - acc: 0.6895 - val_loss: 0.6017 - val_acc: 0.6925\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 1s 511us/step - loss: 0.5882 - acc: 0.7020 - val_loss: 0.5995 - val_acc: 0.7010\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 1s 516us/step - loss: 0.5788 - acc: 0.7065 - val_loss: 0.6060 - val_acc: 0.6960\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 1s 585us/step - loss: 0.5756 - acc: 0.7030 - val_loss: 0.5855 - val_acc: 0.7095\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 1s 552us/step - loss: 0.5647 - acc: 0.7140 - val_loss: 0.5851 - val_acc: 0.7090\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 0.5566 - acc: 0.7140 - val_loss: 0.5792 - val_acc: 0.7095\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 1s 610us/step - loss: 0.5630 - acc: 0.7215 - val_loss: 0.5909 - val_acc: 0.6945\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 1s 522us/step - loss: 0.5504 - acc: 0.7245 - val_loss: 0.7189 - val_acc: 0.6620\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 0.5522 - acc: 0.7175 - val_loss: 0.5984 - val_acc: 0.7175\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 0.5480 - acc: 0.7255 - val_loss: 0.5753 - val_acc: 0.7235\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 1s 621us/step - loss: 0.5438 - acc: 0.7250 - val_loss: 0.5658 - val_acc: 0.7150\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 1s 517us/step - loss: 0.5382 - acc: 0.7230 - val_loss: 0.5650 - val_acc: 0.7140\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 1s 520us/step - loss: 0.5443 - acc: 0.7235 - val_loss: 0.5685 - val_acc: 0.7305\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 1s 547us/step - loss: 0.5345 - acc: 0.7300 - val_loss: 0.5678 - val_acc: 0.7130\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 0.5387 - acc: 0.7200 - val_loss: 0.5929 - val_acc: 0.7065\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 1s 522us/step - loss: 0.5223 - acc: 0.7325 - val_loss: 0.5642 - val_acc: 0.7150\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 1s 514us/step - loss: 0.5185 - acc: 0.7330 - val_loss: 0.5903 - val_acc: 0.7050\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 1s 544us/step - loss: 0.5321 - acc: 0.7245 - val_loss: 0.5595 - val_acc: 0.7195\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 1s 709us/step - loss: 0.5137 - acc: 0.7485 - val_loss: 0.5710 - val_acc: 0.7280\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 0.5210 - acc: 0.7305 - val_loss: 0.5601 - val_acc: 0.7310\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 0.5301 - acc: 0.7390 - val_loss: 0.5672 - val_acc: 0.7235\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 1s 682us/step - loss: 0.5264 - acc: 0.7430 - val_loss: 0.6340 - val_acc: 0.6930\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 0.5236 - acc: 0.7420 - val_loss: 0.5609 - val_acc: 0.7165\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    cb = [\n",
    "        EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto'),\n",
    "        ModelCheckpoint(filepath=weigh_path, verbose=0, save_best_only=True, monitor='val_acc')\n",
    "    ]\n",
    "    elsa_doc.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    test_chose = train_chose\n",
    "    tmp_x = elsa_embedding['en_train_review'] if test_chose else elsa_embedding['en_test_review']\n",
    "    tmp_y = labes['en_train_review'] if test_chose else labes['en_test_review']\n",
    "    test_x = elsa_embedding['en_test_review'] if test_chose else elsa_embedding['en_train_review']\n",
    "    test_y = labes['en_test_review'] if test_chose else labes['en_train_review']\n",
    "    elsa_doc.fit([tmp_x[0], tmp_x[1]], tmp_y, batch_size=batch_size, epochs=epochs, validation_data=([test_x[0], test_x[1]], test_y), verbose=True, callbacks=cb)\n",
    "else:\n",
    "    elsa_doc.load_weights(filepath=pretrained_path)\n",
    "    test_x = elsa_embedding[cur_test[-3:-1:]+'_test_review']\n",
    "    test_y = labes[cur_test[-3:-1:]+'_test_review']\n",
    "    predict_total = elsa_doc.predict([test_x[0], test_x[1]])\n",
    "    predict_total = [int(x > 0.5) for x in predict_total]\n",
    "    acc = accuracy_score(predict_total, test_y)\n",
    "    print(\"%s %s Test Accuracy: %s\\n\" %  (cur_test[:-1], cur_cat[1:], acc))\n",
    "    print(classification_report(test_y, predict_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
